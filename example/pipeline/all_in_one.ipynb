{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fff2170e-92a0-4507-be8c-0ea59ada88a3",
   "metadata": {},
   "source": [
    "![](../../docs/colorful_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c32da6-2647-4446-809b-be93d4dcbefe",
   "metadata": {},
   "source": [
    "# Ananke Pipeline Description\n",
    "![](structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47378e94-4ffa-4ad7-8528-4b5ddee8036a",
   "metadata": {},
   "source": [
    "# Structure Design\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e5f7b1-99df-4c8f-b9f1-a953ad263c64",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b52f17b-8d21-4d7e-ae1e-9c9c29d99f75",
   "metadata": {},
   "source": [
    "## Interaction Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce44a1e-eb87-472a-aa0a-22e5a88227a8",
   "metadata": {},
   "source": [
    "### UserInterface (No in startup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a5e756-120c-4f89-b8c4-c68063bca650",
   "metadata": {},
   "source": [
    "> 在初级的交互式界面中主要使用nodejs + bootstrap\n",
    " \n",
    "\n",
    "[x] 任务需要跑通koodo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b3dc8f-b518-495e-b25a-b5ea0fea8f86",
   "metadata": {},
   "source": [
    "### Client(Local/Web)Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9122c83f-c891-45b9-8881-768522292344",
   "metadata": {},
   "source": [
    "服务发送以内部http request or 直接调用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd988515-691a-4756-b5df-679419d08426",
   "metadata": {},
   "source": [
    "#### Client API\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b685360e-7ede-4c06-8e58-532c54e2e4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67271cb-8e17-413c-b353-cfce5541dcf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3149d9aa-87f1-4806-a0ed-d211923a40c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e645cf-cc8a-4c67-8f88-ff01dc17a8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e75a4f0-08a8-4182-a883-16bbd40e13bd",
   "metadata": {},
   "source": [
    "#### Server API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a735ea9b-2aec-4c0b-9b7f-59bf5e3faa48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1558527-b17e-4fe6-be38-d7bc4fd547b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e256728-3f78-4983-aec9-1b598e7f793e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5adbe02a-2c6b-499d-875d-13802d05bc04",
   "metadata": {},
   "source": [
    "### LLM Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb870ce-e136-49bf-b875-91d782666876",
   "metadata": {},
   "source": [
    "\n",
    "LLM Support List：\n",
    "- OpenAI\n",
    "- Anthropic\n",
    "- Gradient\n",
    "- Hugging Face\n",
    "- EverlyAI\n",
    "- LiteLLM\n",
    "- PaLM\n",
    "- Predibase\n",
    "- Replicate\n",
    "- LangChain\n",
    "- Llama API\n",
    "- Llama CPP\n",
    "- Xorbits Inference\n",
    "- MonsterAPI\n",
    "- RunGPT\n",
    "- Portkey\n",
    "- AnyScale\n",
    "- Ollama\n",
    "- Konko"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377b6ace-d512-4acf-8f19-69be132a2d6d",
   "metadata": {},
   "source": [
    "### Context Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669855b0-c86b-47f4-8d6d-75a067b9e02e",
   "metadata": {},
   "source": [
    "主要分为Context构造压缩重复存储&结构化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da654e9e-1e8a-4bf8-b402-b5537b1b4997",
   "metadata": {},
   "source": [
    "#### Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdf7e75-5d08-45ee-b087-0b92bf3ede4b",
   "metadata": {},
   "source": [
    "在传统的定义模式中类似langchain & llamaindex 他们的prompt实现忽视了不同阶段的定义例子如下\n",
    "```python\n",
    "from llama_index.llms import ChatMessage, MessageRole\n",
    "from llama_index.prompts import ChatPromptTemplate\n",
    "\n",
    "# Text QA Prompt\n",
    "chat_text_qa_msgs = [\n",
    "    ChatMessage(\n",
    "        role=MessageRole.SYSTEM,\n",
    "        content=\"Always answer the question, even if the context isn't helpful.\",\n",
    "    ),\n",
    "    ChatMessage(\n",
    "        role=MessageRole.USER,\n",
    "        content=(\n",
    "            \"Context information is below.\\n\"\n",
    "            \"---------------------\\n\"\n",
    "            \"{context_str}\\n\"\n",
    "            \"---------------------\\n\"\n",
    "            \"Given the context information and not prior knowledge, \"\n",
    "            \"answer the question: {query_str}\\n\"\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "text_qa_template = ChatPromptTemplate(chat_text_qa_msgs)\n",
    "```\n",
    "这种定义形式忽略了初始prompt和持续对话prompt对定义的不同需求，即初始定义为可选项，在前向对话的时候引入另一组prompt预设。当然随着历史对话的增长输出性能会随之下降\n",
    "大量的情况，在固定context长度的时候这种长对话不建议超过max token\n",
    "\n",
    "**** \n",
    "因此在框架中引入了下列新的构造形式："
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d8b2f78-d37b-4ca6-83ce-023d229f7065",
   "metadata": {},
   "source": [
    "\n",
    "from ananke.prompt import Prompt\n",
    "prompt = Prompt()\n",
    "\n",
    "instructed_init_prompt = \"\"\"\n",
    "The below text is you need to process\n",
    "```markdown\n",
    "{text}\n",
    "{extra_param}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "instructed_forward_prompt = \"\"\"\n",
    "The below data is you need process:\n",
    "```\n",
    "Nodes:\n",
    "```\n",
    "{nodes}\n",
    "```\n",
    "Relationships:\n",
    "```\n",
    "{relationships}\n",
    "```\n",
    "questions or sentences:\n",
    "```\n",
    "{user_input}\n",
    "\"\"\"\n",
    "\n",
    "prompt.set_template(instructed_init_prompt, instructed_forward_prompt)\n",
    "\n",
    "init_formatted_prompt = prompt.init(text=\"Sample text to process\", extra_param=\"Extra parameter\")\n",
    "forward_formatted_prompt = prompt(nodes=\"Node data\", relationships=\"Relationship data\", user_input=\"User input\")\n",
    "\n",
    "print(\"Initialized Prompt:\")\n",
    "print(init_formatted_prompt)\n",
    "\n",
    "print(\"\\nForward Prompt:\")\n",
    "print(forward_formatted_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad16e1c-744b-4dec-8594-997f5d273255",
   "metadata": {},
   "source": [
    "因此我们可以看到这个结构充分的扩展了构造结果的适用性\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3955b3-80c6-444b-9bb8-0f3a9ab28f9d",
   "metadata": {},
   "source": [
    "#### Compressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b7b016-e4a2-4e0d-a3f4-7027d07a6406",
   "metadata": {},
   "source": [
    "这类问题主要源于针对某一问题的context压缩,这一问题的主要来源是我们通常并不能从一个给定的向量数据库查询结果的文章段落中很好的突出重点信息。而和问题相关的内容通常只占相关段落的很少一部分，因此需要对context进行筛选和压缩\n",
    "\n",
    "One challenge with retrieval is that usually you don't know the specific queries your document storage system will face when you ingest data into the system. This means that the information most relevant to a query may be buried in a document with a lot of irrelevant text. Passing that full document through your application can lead to more expensive LLM calls and poorer responses.\n",
    "\n",
    "Contextual compression is meant to fix this. The idea is simple: instead of immediately returning retrieved documents as-is, you can compress them using the context of the given query, so that only the relevant information is returned. “Compressing” here refers to both compressing the contents of an individual document and filtering out documents wholesale.\n",
    "\n",
    "To use the Contextual Compression Retriever, you'll need:\n",
    "\n",
    "* a base retriever\n",
    "* a Document Compressor\n",
    "The Contextual Compression Retriever passes queries to the base retriever, takes the initial documents and passes them through the Document Compressor. The Document Compressor takes a list of documents and shortens it by reducing the contents of documents or dropping documents altogether.\n",
    "\n",
    "![](compressor.jpg)\n",
    "\n",
    "下面是一个langchain的官方案例：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd15ad7-b015-4b4f-9c72-934f453cb1f3",
   "metadata": {},
   "source": [
    "```python\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "documents = TextLoader('../../../state_of_the_union.txt').load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "retriever = FAISS.from_documents(texts, OpenAIEmbeddings()).as_retriever()\n",
    "\n",
    "docs = retriever.get_relevant_documents(\"What did the president say about Ketanji Brown Jackson\")\n",
    "pretty_print_docs(docs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804f3e4c-28c9-4dab-a412-62a0a94ec05e",
   "metadata": {},
   "source": [
    "```markdown\n",
    "    Document 1:\n",
    "    \n",
    "    Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \n",
    "    \n",
    "    Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n",
    "    \n",
    "    One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
    "    \n",
    "    And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n",
    "    ----------------------------------------------------------------------------------------------------\n",
    "    Document 2:\n",
    "    \n",
    "    A former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she’s been nominated, she’s received a broad range of support—from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n",
    "    \n",
    "    And if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n",
    "    \n",
    "    We can do both. At our border, we’ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n",
    "    \n",
    "    We’ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n",
    "    \n",
    "    We’re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \n",
    "    \n",
    "    We’re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.\n",
    "    ----------------------------------------------------------------------------------------------------\n",
    "    Document 3:\n",
    "    \n",
    "    And for our LGBTQ+ Americans, let’s finally get the bipartisan Equality Act to my desk. The onslaught of state laws targeting transgender Americans and their families is wrong. \n",
    "    \n",
    "    As I said last year, especially to our younger transgender Americans, I will always have your back as your President, so you can be yourself and reach your God-given potential. \n",
    "    \n",
    "    While it often appears that we never agree, that isn’t true. I signed 80 bipartisan bills into law last year. From preventing government shutdowns to protecting Asian-Americans from still-too-common hate crimes to reforming military justice. \n",
    "    \n",
    "    And soon, we’ll strengthen the Violence Against Women Act that I first wrote three decades ago. It is important for us to show the nation that we can come together and do big things. \n",
    "    \n",
    "    So tonight I’m offering a Unity Agenda for the Nation. Four big things we can do together.  \n",
    "    \n",
    "    First, beat the opioid epidemic.\n",
    "    ----------------------------------------------------------------------------------------------------\n",
    "    Document 4:\n",
    "    \n",
    "    Tonight, I’m announcing a crackdown on these companies overcharging American businesses and consumers. \n",
    "    \n",
    "    And as Wall Street firms take over more nursing homes, quality in those homes has gone down and costs have gone up.  \n",
    "    \n",
    "    That ends on my watch. \n",
    "    \n",
    "    Medicare is going to set higher standards for nursing homes and make sure your loved ones get the care they deserve and expect. \n",
    "    \n",
    "    We’ll also cut costs and keep the economy going strong by giving workers a fair shot, provide more training and apprenticeships, hire them based on their skills not degrees. \n",
    "    \n",
    "    Let’s pass the Paycheck Fairness Act and paid leave.  \n",
    "    \n",
    "    Raise the minimum wage to $15 an hour and extend the Child Tax Credit, so no one has to raise a family in poverty. \n",
    "    \n",
    "    Let’s increase Pell Grants and increase our historic support of HBCUs, and invest in what Jill—our First Lady who teaches full-time—calls America’s best-kept secret: community colleges.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cf3a03-c64d-4992-916e-f081256c893f",
   "metadata": {},
   "source": [
    "我们可以看到，给定一个示例问题，我们的检索器返回一两个相关文档和一些不相关的文档。甚至相关文档中也有很多不相关的信息。这对于整个内容的后续交互和生成是极其不必要的，在langchain中内置了很多压缩和过滤的模块\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56af4cc6-fce1-4392-80a5-7ea0d12f5aa6",
   "metadata": {},
   "source": [
    "* LLMChainFilter\n",
    "\n",
    "The LLMChainFilter is slightly simpler but more robust compressor that uses an LLM chain to decide which of the initially retrieved documents to filter out and which ones to return, without manipulating the document contents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7d2d63-258b-4260-9284-4e2746541b43",
   "metadata": {},
   "source": [
    "* EmbeddingsFilter\n",
    "\n",
    "Making an extra LLM call over each retrieved document is expensive and slow. The EmbeddingsFilter provides a cheaper and faster option by embedding the documents and query and only returning those documents which have sufficiently similar embeddings to the query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75989475-00da-4857-a47e-2219f76280c8",
   "metadata": {},
   "source": [
    "* Stringing compressors and document transformers together\n",
    "\n",
    "Using the DocumentCompressorPipeline we can also easily combine multiple compressors in sequence. Along with compressors we can add BaseDocumentTransformers to our pipeline, which don't perform any contextual compression but simply perform some transformation on a set of documents. For example TextSplitters can be used as document transformers to split documents into smaller pieces, and the EmbeddingsRedundantFilter can be used to filter out redundant documents based on embedding similarity between documents.\n",
    "\n",
    "Below we create a compressor pipeline by first splitting our docs into smaller chunks, then removing redundant documents, and then filtering based on relevance to the query.\n",
    "\n",
    "```python\n",
    "from langchain.document_transformers import EmbeddingsRedundantFilter\n",
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0, separator=\". \")\n",
    "redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings)\n",
    "relevant_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.76)\n",
    "pipeline_compressor = DocumentCompressorPipeline(\n",
    "    transformers=[splitter, redundant_filter, relevant_filter]\n",
    ")\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cb0e70-f425-4066-8ed9-76cd223e3294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c134dc50-7db3-496f-815c-5a3ddb5b3187",
   "metadata": {},
   "source": [
    "#### TempStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b4bb20-925c-4923-9420-5d0b0f131909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49513e8a-9e64-465d-ab14-bb7807c67a1d",
   "metadata": {},
   "source": [
    "#### ContextStructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fded18d-ad41-404b-89b2-50e27cfef1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "405c5af6-d729-4196-b249-8f477c03af9f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "591b4c14-f8bf-4a65-8dca-23affd9e91ee",
   "metadata": {},
   "source": [
    "## Document Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b75c6ff-f916-4083-a07a-9477b7dc63b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e04fc097-dfe9-4904-abec-53676202006c",
   "metadata": {},
   "source": [
    "### Unified DocumentLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed763adf-6805-448e-8102-2f739923e113",
   "metadata": {},
   "source": [
    "集成式的数据加载需要针对不同的数据类型和记录,以PDF为例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a75c590-84fe-4654-8e9e-eeeccaf13f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF1=\"2306.08302.pdf\"\n",
    "PDF2=\"2307.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1322c7a5-4fe0-44bb-8fb0-85101ab2a601",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'paddleocr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munstructured\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UnstructuredFileLoader\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpaddleocr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PaddleOCR\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfitz\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mUnstructuredPaddlePDFLoader\u001b[39;00m(UnstructuredFileLoader):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'paddleocr'"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from langchain.document_loaders.unstructured import UnstructuredFileLoader\n",
    "from paddleocr import PaddleOCR\n",
    "import fitz\n",
    "\n",
    "\n",
    "\n",
    "class UnstructuredPaddlePDFLoader(UnstructuredFileLoader):\n",
    "    \"\"\"Loader that uses unstructured to load image files, such as PNGs and JPGs.\"\"\"\n",
    "\n",
    "    def _get_elements(self) -> List:\n",
    "        def pdf_ocr_txt(filepath, dir_path=\"tmp_files\"):\n",
    "            full_dir_path = os.path.join(os.path.dirname(filepath), dir_path)\n",
    "            if not os.path.exists(full_dir_path):\n",
    "                os.makedirs(full_dir_path)\n",
    "            ocr = PaddleOCR(use_angle_cls=True, lang=\"ch\", use_gpu=False, show_log=False)\n",
    "            doc = fitz.open(filepath)\n",
    "            txt_file_path = os.path.join(full_dir_path, f\"{os.path.split(filepath)[-1]}.txt\")\n",
    "            img_name = os.path.join(full_dir_path, 'tmp.png')\n",
    "            with open(txt_file_path, 'w', encoding='utf-8') as fout:\n",
    "                for i in range(doc.page_count):\n",
    "                    page = doc[i]\n",
    "                    text = page.get_text(\"\")\n",
    "                    fout.write(text)\n",
    "                    fout.write(\"\\n\")\n",
    "\n",
    "                    img_list = page.get_images()\n",
    "                    for img in img_list:\n",
    "                        pix = fitz.Pixmap(doc, img[0])\n",
    "                        if pix.n - pix.alpha >= 4:\n",
    "                            pix = fitz.Pixmap(fitz.csRGB, pix)\n",
    "                        pix.save(img_name)\n",
    "\n",
    "                        result = ocr.ocr(img_name)\n",
    "                        ocr_result = [i[1][0] for line in result for i in line]\n",
    "                        fout.write(\"\\n\".join(ocr_result))\n",
    "            if os.path.exists(img_name):\n",
    "                os.remove(img_name)\n",
    "            return txt_file_path\n",
    "\n",
    "        txt_file_path = pdf_ocr_txt(self.file_path)\n",
    "        from unstructured.partition.text import partition_text\n",
    "        return partition_text(filename=txt_file_path, **self.unstructured_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfa6297-bcaf-4d8b-bed0-0cac37c53aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredPaddlePDFLoader(filepath, mode=\"elements\")\n",
    "docs = loader.load()\n",
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c043f1-fc4a-4d5e-9454-538ec7fe5008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527a90da-37f5-4bcd-913e-09e593927e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68bdd482-2001-426f-8dc3-aac058e9b6be",
   "metadata": {},
   "source": [
    "### pecific Document Spilit & Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e571bb6-32d9-4ce6-8036-fabd88d06c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e02ba16d-0b04-4070-8493-ac54ef8dc0b7",
   "metadata": {},
   "source": [
    "### MetaParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ee53c8-8ded-4c1c-9c18-062012892d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "081fcac2-d6dc-4ebd-995d-119ae053034d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0a5c069-d991-435c-980b-56d4ed854fec",
   "metadata": {},
   "source": [
    "## Compute System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ae3b22-9904-4dc2-8648-31cbcc592080",
   "metadata": {},
   "source": [
    "### StructuredChunks Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad365ab-3a83-4edb-a0ef-abcd272c4e85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83293211-3a7b-45ad-a12e-2f46de598fbe",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9292b995-3a66-41cb-a1e2-15200ec2828d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e838318c-1f89-4720-9b3c-a74573ea4baf",
   "metadata": {},
   "source": [
    "### Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8b2558-acc3-431c-9001-fe5856e4b7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0596be9a-583e-4a5d-92d7-bbd9b0acdeaf",
   "metadata": {},
   "source": [
    "#### Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fe7b40-7756-4f64-9255-3d19b12f308e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fead7e9-e3f1-4d56-91a7-8ac023872422",
   "metadata": {},
   "source": [
    "## Storage System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b638ac6-0b2d-46c2-a7e9-4beda3125cc9",
   "metadata": {},
   "source": [
    "### VectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac59b30c-631a-445a-8aaf-23ae8ac04f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1eac8e46-3fb9-4470-a675-500bcbdb196e",
   "metadata": {},
   "source": [
    "#### Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae6caff-dc10-4bf0-9e7a-5eacd1493d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "197c88ac-61d8-4649-a7d4-6dbea18b1d6a",
   "metadata": {},
   "source": [
    "### Graph(Structure)DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c0a019-0647-4dbd-ba6a-f95f2e2eabef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd4c35cf-ff6b-4773-880f-5773f95ce0f0",
   "metadata": {},
   "source": [
    "#### Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b22b36e-6a3a-4801-a108-302452d6980a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc525c4-a50b-4eca-ab33-872daf2ab4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ff0854a-d93b-4257-a71f-16a021a5311c",
   "metadata": {},
   "source": [
    "#### Nebula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b406023-b28f-4c28-992a-36d9af852bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14e5dd19-1f06-40c0-9673-b7d4012ba21a",
   "metadata": {},
   "source": [
    "### RelationDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3647cb74-aefa-48be-8210-dbfacfccf22f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "927f35f3-a066-4a60-988d-83fd037cb8cc",
   "metadata": {},
   "source": [
    "#### Sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161e088b-244c-494f-9a2a-3e274bff4e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1bd9494-3c53-43db-b56e-4a23dcb53b52",
   "metadata": {},
   "source": [
    "#### MariaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc78de8d-bd22-4196-b51e-a018c0e3f2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4964f85-3ecf-4efa-b16a-9ff89440f35c",
   "metadata": {},
   "source": [
    "# Final Interaction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5fb8d4-baa7-485c-93ed-468ad84f58fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
