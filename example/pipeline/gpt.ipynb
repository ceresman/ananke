{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4ac8af8-ed17-426b-92ce-60d46f595579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}, 'finish_reason': 'stop', 'index': 0, 'message': {'content': '这张图是Ananke.DB的系统架构图。Ananke.DB是一个用于实现多表示索引数据框架的结构设计。它具有以下特点：\\n\\n1. 与LLM（大型语言模型）完全兼容的交互设计。\\n2. 基于图的关系知识表示。\\n3. 向量表示和图表示之间的索引。\\n\\n系统分为三个主要部分：生产者（Producer）、计算系统（Compute System）和消费者（Consumer）。\\n\\n在生产者部分，有一个交互管道（Interaction Pipeline）和文档管道（Document Pipeline）。交互管道处理用户界面（User-Interface）输入的聊天消息（Chat Message）并结合聊天上下文（Chat Context）生成结果。文档管道处理文档的元数据（Document Meta），分析和解码文档内容，并将文档分割为页面/块/章节列表。\\n\\n计算系统部分包括信息压缩嵌入模块（Info compress Embedding Module）和LLM图生成器（LLM Graph Generator），以及表示构建（Representation construction）模块，它们负责生成嵌入抽象（Embedding Abstract）和编码器/解码器（Encoder/Decoder）。\\n\\n消费者部分则涉及到结构块（Structure Chunks），包括图（graph）的元数据（Meta）、关系（Relationships）、节点（Nodes）以及向量/字节（Vector/Bytes）。此部分还包括存储系统（Storage System），其中包括Neo4j服务器/后端、记录存储引擎（RecordStorageEngine）、Cypher查询语言、HNSWChroma以及其他与数据库和索引相关的组件。\\n\\n整个系统设计旨在实现高效的数据处理和检索功能，同时保持与现代大型语言模型的兼容性。', 'role': 'assistant'}}], 'created': 0, 'id': '', 'model': '', 'object': 'chat.completion', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'low'}, 'violence': {'filtered': False, 'severity': 'safe'}}}]}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import base64\n",
    "\n",
    "# Configuration\n",
    "GPT4V_KEY = \"\"\n",
    "IMAGE_PATH = \"/workspace/tanwnexuan/ananke/example/pipeline/structure.png\"\n",
    "# encoded_image = base64.b64encode(open(IMAGE_PATH, 'rb').read()).decode('ascii')\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"api-key\": GPT4V_KEY,\n",
    "}\n",
    "import base64\n",
    "from mimetypes import guess_type\n",
    "\n",
    "# Function to encode a local image into data URL \n",
    "def local_image_to_data_url(image_path):\n",
    "    # Guess the MIME type of the image based on the file extension\n",
    "    mime_type, _ = guess_type(image_path)\n",
    "    if mime_type is None:\n",
    "        mime_type = 'application/octet-stream'  # Default MIME type if none is found\n",
    "\n",
    "    # Read and encode the image file\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_encoded_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    # Construct the data URL\n",
    "    return f\"data:{mime_type};base64,{base64_encoded_data}\"\n",
    "\n",
    "# Payload for the request\n",
    "payload = {\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"这张图在讲什么.\"\n",
    "        },\n",
    "         { \n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": local_image_to_data_url(IMAGE_PATH)\n",
    "                }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"temperature\": 0.7,\n",
    "  \"top_p\": 0.95,\n",
    "  \"max_tokens\": 800\n",
    "}\n",
    "\n",
    "GPT4V_ENDPOINT = \"\"\n",
    "# Send request\n",
    "try:\n",
    "    response = requests.post(GPT4V_ENDPOINT, headers=headers, json=payload)\n",
    "    response.raise_for_status()  # Will raise an HTTPError if the HTTP request returned an unsuccessful status code\n",
    "except requests.RequestException as e:\n",
    "    raise SystemExit(f\"Failed to make the request. Error: {e}\")\n",
    "\n",
    "# Handle the response as needed (e.g., print or process)\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ed575eb-b234-4758-9bb8-c0c9414a694d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from local image: {'choices': [{'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}, 'finish_reason': 'stop', 'index': 0, 'message': {'content': '这张图表示的是RetNet的双重形式，即并行表示（a）和循环表示（b）。这与Transformer模型有一些关键区别：\\n\\n1. 结构设计：图中的并行表示（a）显示了一个类似于Transformer中的自注意力机制（Self-Attention）的结构，其中Q、K、V分别代表查询（Query）、键（Key）和值（Value），并通过点乘和GroupNorm（GN）进行操作。然而，Transformer的自注意力机制通常会包含多头注意力（Multi-Head Attention），并且使用LayerNorm而不是GroupNorm。\\n\\n2. 循环连接：图中的循环表示（b）展示了一种循环神经网络（Recurrent Neural Network, RNN）的结构，其中包含循环状态（Recurrent State）和时序输入（Input）。这种结构在标准的Transformer模型中是不存在的，因为Transformer通常使用并行处理来处理序列数据，而不是循环连接。\\n\\n3. GroupNorm：图中使用了GroupNorm（组归一化），这是一种归一化技术，常用于卷积神经网络（CNN）中。而Transformer通常使用LayerNorm（层归一化）作为其标准归一化方法。\\n\\n4. 输出处理：图中的循环表示中，输出（Output）通过一个附加的门控单元（G）进行处理。这种结构在标准的Transformer模型中也不常见，Transformer模型的输出通常直接由自注意力机制和前馈网络（Feed-Forward Network）生成。\\n\\n综上所述，这张图表示的RetNet模型在结构设计、归一化技术和输出处理等方面与Transformer有显著区别。特别是循环表示部分，它引入了RNN的特性，这在标准的Transformer模型中是不包含的。', 'role': 'assistant'}}], 'created': 0, 'id': '', 'model': '', 'object': 'chat.completion', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import base64\n",
    "from mimetypes import guess_type\n",
    "\n",
    "class GPT4VClient:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"api-key\": api_key,\n",
    "        }\n",
    "        self.endpoint = \"https://anankesweden.openai.azure.com/openai/deployments/AnankeVision/chat/completions?api-version=2023-07-01-preview\"\n",
    "\n",
    "    def request_with_url_image(self, image_url, prompt):\n",
    "        payload = self._build_payload_with_image_url(image_url, prompt)\n",
    "        return self._send_request(payload)\n",
    "\n",
    "    def request_with_local_image(self, image_path, prompt):\n",
    "        payload = self._build_payload_with_local_image(image_path, prompt)\n",
    "        return self._send_request(payload)\n",
    "\n",
    "    def _build_payload_with_image_url(self, image_url, prompt):\n",
    "        payload = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": image_url\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_p\": 0.95,\n",
    "            \"max_tokens\": 800\n",
    "        }\n",
    "        return payload\n",
    "\n",
    "    def _build_payload_with_local_image(self, image_path, prompt):\n",
    "        mime_type, _ = guess_type(image_path)\n",
    "        if mime_type is None:\n",
    "            mime_type = 'application/octet-stream'\n",
    "\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            base64_encoded_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "        payload = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:{mime_type};base64,{base64_encoded_data}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_p\": 0.95,\n",
    "            \"max_tokens\": 800\n",
    "        }\n",
    "        return payload\n",
    "\n",
    "    def _send_request(self, payload):\n",
    "        try:\n",
    "            response = requests.post(self.endpoint, headers=self.headers, json=payload)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.RequestException as e:\n",
    "            raise SystemExit(f\"Failed to make the request. Error: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "api_key = \"45d24fc4b19047eaa81632eb76dc0fa9\"\n",
    "client = GPT4VClient(api_key)\n",
    "# image_url_response = client.request_with_url_image(\"https://miro.medium.com/max/1400/1*BHzGVskWGS_3jEcYYi6miQ.png\", \"这张图在讲什么.\")\n",
    "# print(\"Response from URL image:\", image_url_response)\n",
    "local_image_response = client.request_with_local_image(\"/workspace/tanwnexuan/ananke/example/pipeline/ret.png\", \"这张图和transformer有什么区别.\")\n",
    "print(\"Response from local image:\", local_image_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455fb21e-dec5-44cb-8c3f-e9475b73a1c6",
   "metadata": {},
   "source": [
    "![](./ret.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcdbf45-5c62-40d3-99d9-c3b81eefa23a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
