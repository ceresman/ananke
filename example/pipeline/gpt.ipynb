{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ed575eb-b234-4758-9bb8-c0c9414a694d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from local image: {'id': 'chatcmpl-8xbm3rQ0E2XkU9K3g91GBpV4h07Cl', 'object': 'chat.completion', 'created': 1709217247, 'model': 'gpt-4', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'role': 'assistant', 'content': '这张图展示了RetNet的两种表示形式：并行表示和循环表示。RetNet是一种注意力机制，它将传统的Transformer中的自注意力（self-attention）模块替换为一个轻量级的递归模块。在这张图中，我们可以看到两种不同的表示形式，它们都具有Q（查询）、K（键）、V（值）这三个主要组件，这些组件是Transformer中自注意力机制的基础。\\n\\n(a) 部分显示的是并行表示，其中输入X被分解为Q、K、V三个部分，然后通过点积和按元素乘法（表示为∘）来计算注意力权重，最后将这些权重应用到V上得到输出O。输出O在通过GroupNorm（表示为GN）标准化后得到最终结果。\\n\\n(b) 部分则展示了循环表示，其中引入了一个循环状态S，它在不同的时间步之间传递信息。每个时间步n，输入Xn更新循环状态Sn，并且使用循环状态来计算新的Qn、Kn和Vn。这些组件通过相似的注意力机制来更新状态，并最终产生输出On。\\n\\n与标准的Transformer相比，这里的主要区别在于RetNet使用了循环表示来处理序列数据，而不是标准Transformer中的自注意力机制。此外，RetNet通过替换成循环结构，减少了模型的计算复杂性，使其更适合于处理长序列和实时应用场景。此外，RetNet使用GroupNorm而不是Transformer通常使用的LayerNorm来进行标准化。'}, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'usage': {'prompt_tokens': 1125, 'completion_tokens': 455, 'total_tokens': 1580}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import base64\n",
    "from mimetypes import guess_type\n",
    "\n",
    "class GPT4VClient:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"api-key\": api_key,\n",
    "        }\n",
    "        self.endpoint = \"https://anankesweden.openai.azure.com/openai/deployments/AnankeVision/chat/completions?api-version=2023-07-01-preview\"\n",
    "\n",
    "    def request_with_url_image(self, image_url, prompt):\n",
    "        payload = self._build_payload_with_image_url(image_url, prompt)\n",
    "        return self._send_request(payload)\n",
    "\n",
    "    def request_with_local_image(self, image_path, prompt):\n",
    "        payload = self._build_payload_with_local_image(image_path, prompt)\n",
    "        return self._send_request(payload)\n",
    "\n",
    "    def _build_payload_with_image_url(self, image_url, prompt):\n",
    "        payload = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": image_url\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_p\": 0.95,\n",
    "            \"max_tokens\": 800\n",
    "        }\n",
    "        return payload\n",
    "\n",
    "    def _build_payload_with_local_image(self, image_path, prompt):\n",
    "        mime_type, _ = guess_type(image_path)\n",
    "        if mime_type is None:\n",
    "            mime_type = 'application/octet-stream'\n",
    "\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            base64_encoded_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "        payload = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:{mime_type};base64,{base64_encoded_data}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_p\": 0.95,\n",
    "            \"max_tokens\": 800\n",
    "        }\n",
    "        return payload\n",
    "\n",
    "    def _send_request(self, payload):\n",
    "        try:\n",
    "            response = requests.post(self.endpoint, headers=self.headers, json=payload)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.RequestException as e:\n",
    "            raise SystemExit(f\"Failed to make the request. Error: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "api_key = \"45d24fc4b19047eaa81632eb76dc0fa9\"\n",
    "client = GPT4VClient(api_key)\n",
    "# image_url_response = client.request_with_url_image(\"https://miro.medium.com/max/1400/1*BHzGVskWGS_3jEcYYi6miQ.png\", \"这张图在讲什么.\")\n",
    "# print(\"Response from URL image:\", image_url_response)\n",
    "local_image_response = client.request_with_local_image(\"/workspace/tanwnexuan/ananke/example/pipeline/ret.png\", \"这张图和transformer有什么区别.\")\n",
    "print(\"Response from local image:\", local_image_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455fb21e-dec5-44cb-8c3f-e9475b73a1c6",
   "metadata": {},
   "source": [
    "![](./ret.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfcdbf45-5c62-40d3-99d9-c3b81eefa23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8xbmGalhWoUSzmIga0FYxeMUKuZzF', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Hello! How can I assist you today?', role='assistant', function_call=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}, logprobs=None)], created=1709217260, model='gpt-35-turbo', object='chat.completion', usage=CompletionUsage(completion_tokens=9, prompt_tokens=18, total_tokens=27), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], system_fingerprint='fp_68a7d165bf')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = \"https://anankeus.openai.azure.com/\", \n",
    "  api_key=\"61bc1aab37364618ae0df70bf5f340dd\",  \n",
    "  api_version=\"2024-02-15-preview\"\n",
    ")\n",
    "\n",
    "\n",
    "message_text = [{\"role\":\"system\",\"content\":\"You are an AI assistant that helps people find information.\"}]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"Ananke3-1106-US-WEST\", # model = \"deployment_name\"\n",
    "  messages = message_text,\n",
    "  temperature=0.7,\n",
    "  max_tokens=800,\n",
    "  top_p=0.95,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    "  stop=None\n",
    ")\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c8bad9d-973c-4c33-863c-75f9524d843f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='\"精准智绘，未来从此触手可及 —— 智谱AI，赋能想象。\"' role='assistant' tool_calls=None\n"
     ]
    }
   ],
   "source": [
    "from zhipuai import ZhipuAI\n",
    "client = ZhipuAI(api_key=\"6d1e089b49d9a1fc9f251240af39d2ff.sEjOi7HBGjQML5pf\") # 填写您自己的APIKey\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\",  # 填写需要调用的模型名称\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"作为一名营销专家，请为我的产品创作一个吸引人的slogan\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"当然，为了创作一个吸引人的slogan，请告诉我一些关于您产品的信息\"},\n",
    "        {\"role\": \"user\", \"content\": \"智谱AI开放平台\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"智启未来，谱绘无限一智谱AI，让创新触手可及!\"},\n",
    "        {\"role\": \"user\", \"content\": \"创造一个更精准、吸引人的slogan\"}\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76f17da8-636c-4702-92d2-0da873aec6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content='\"精准智绘，未来从此触手可及 —— 智谱AI，赋能想象。\"', role='assistant', tool_calls=None))]\n"
     ]
    }
   ],
   "source": [
    "print(response.choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da98dfe-27a1-4d3b-8085-80a4110c7bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
