{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9adb0de-594e-4b34-be42-a83be955e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da09846c-f4ce-4672-b6e1-a35ee2a3b7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#基础逻辑理解清楚了，现在得notebook把代码来跑通来\n",
    "import argparse\n",
    "import logging\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import pytz\n",
    "import shutil\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "431e53f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='LEGO-Prover')\n",
    "parser.add_argument('--resume', action='store_true',\n",
    "                    help='whether to resume from the checkpoint')\n",
    "parser.add_argument('--data_split', type=str, choices=['valid', 'test'], \n",
    "                    default='valid', help='data split to use in the miniF2F dataset')\n",
    "parser.add_argument('--ckpt_dir', type=str, default='checkpoints/lego_prover_valid_2023_10_27',\n",
    "                    help='path to the checkpoint directory')\n",
    "parser.add_argument('--isabelle_path', type=str, default='/data2/wanghaiming/Isabelle2022/',\n",
    "                    help='path to the Isabelle2022 directory')\n",
    "parser.add_argument('--model_name', type=str, choices=[\"gpt-3.5-turbo\", \"gpt-4\"], \n",
    "                    default='gpt-3.5-turbo', help='OpenAI model name')\n",
    "parser.add_argument('--temperature', type=float, default=0.7,\n",
    "                    help='temperature for sampling the LLM')\n",
    "parser.add_argument('--num_prover', type=int, default=3,\n",
    "                    help='number of prover processes')\n",
    "parser.add_argument('--num_evolver', type=int, default=8,\n",
    "                    help='number of evolver processes')\n",
    "parser.add_argument('--num_attempts', type=int, default=100,\n",
    "                    help='number of proving attempts for each problem in the dataset')\n",
    "args = parser.parse_args([])\n",
    "# for arg in args:\n",
    "#     print(arg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da4a6512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "the checkpoint directory checkpoints/lego_prover_valid_2023_10_27 is already exist, andyou are not resuming from it, do you want to delete it? (y/n) y\n"
     ]
    }
   ],
   "source": [
    "resume = args.resume\n",
    "data_split = args.data_split\n",
    "ckpt_dir = args.ckpt_dir\n",
    "isabelle_path = args.isabelle_path\n",
    "model_name = args.model_name\n",
    "temperature = args.temperature\n",
    "number_of_prover_processes = args.num_prover\n",
    "number_of_evolver_processes = args.num_evolver\n",
    "number_of_prover_attempts = args.num_attempts\n",
    "\n",
    "if os.path.exists(ckpt_dir) and not resume:\n",
    "    text = input(f\"the checkpoint directory {ckpt_dir} is already exist, and\" + \\\n",
    "                 f\"you are not resuming from it, do you want to delete it? (y/n)\")\n",
    "    if \"y\" in text.lower():\n",
    "        shutil.rmtree(ckpt_dir, ignore_errors=True)\n",
    "        resume = False\n",
    "    else:\n",
    "        resume = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1940bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## file utils\n",
    "\"\"\"\n",
    "File system utils.\n",
    "\"\"\"\n",
    "import collections\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import errno\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "# import pwd\n",
    "import codecs\n",
    "import hashlib\n",
    "import tarfile\n",
    "import fnmatch\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "from socket import gethostname\n",
    "import logging\n",
    "\n",
    "\n",
    "f_ext = os.path.splitext\n",
    "\n",
    "f_size = os.path.getsize\n",
    "\n",
    "is_file = os.path.isfile\n",
    "\n",
    "is_dir = os.path.isdir\n",
    "\n",
    "get_dir = os.path.dirname\n",
    "\n",
    "\n",
    "def host_name():\n",
    "    \"Get host name, alias with ``socket.gethostname()``\"\n",
    "    return gethostname()\n",
    "\n",
    "\n",
    "def host_id():\n",
    "    \"\"\"\n",
    "    Returns: first part of hostname up to '.'\n",
    "    \"\"\"\n",
    "    return host_name().split(\".\")[0]\n",
    "\n",
    "\n",
    "def utf_open(fname, mode):\n",
    "    \"\"\"\n",
    "    Wrapper for codecs.open\n",
    "    \"\"\"\n",
    "    return codecs.open(fname, mode=mode, encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "def is_sequence(obj):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      True if the sequence is a collections.Sequence and not a string.\n",
    "    \"\"\"\n",
    "    return isinstance(obj, collections.abc.Sequence) and not isinstance(obj, str)\n",
    "\n",
    "\n",
    "def pack_varargs(args):\n",
    "    \"\"\"\n",
    "    Pack *args or a single list arg as list\n",
    "\n",
    "    def f(*args):\n",
    "        arg_list = pack_varargs(args)\n",
    "        # arg_list is now packed as a list\n",
    "    \"\"\"\n",
    "    assert isinstance(args, tuple), \"please input the tuple `args` as in *args\"\n",
    "    if len(args) == 1 and is_sequence(args[0]):\n",
    "        return args[0]\n",
    "    else:\n",
    "        return args\n",
    "\n",
    "\n",
    "def f_not_empty(*fpaths):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        True if and only if the file exists and file size > 0\n",
    "          if fpath is a dir, if and only if dir exists and has at least 1 file\n",
    "    \"\"\"\n",
    "    fpath = f_join(*fpaths)\n",
    "    if not os.path.exists(fpath):\n",
    "        return False\n",
    "\n",
    "    if os.path.isdir(fpath):\n",
    "        return len(os.listdir(fpath)) > 0\n",
    "    else:\n",
    "        return os.path.getsize(fpath) > 0\n",
    "\n",
    "\n",
    "def f_expand(fpath):\n",
    "    return os.path.expandvars(os.path.expanduser(fpath))\n",
    "\n",
    "\n",
    "def f_exists(*fpaths):\n",
    "    return os.path.exists(f_join(*fpaths))\n",
    "\n",
    "\n",
    "def f_join(*fpaths):\n",
    "    \"\"\"\n",
    "    join file paths and expand special symbols like `~` for home dir\n",
    "    \"\"\"\n",
    "    fpaths = pack_varargs(fpaths)\n",
    "    fpath = f_expand(os.path.join(*fpaths))\n",
    "    if isinstance(fpath, str):\n",
    "        fpath = fpath.strip()\n",
    "    return fpath\n",
    "\n",
    "\n",
    "def f_listdir(\n",
    "    *fpaths,\n",
    "    filter_ext=None,\n",
    "    filter=None,\n",
    "    sort=True,\n",
    "    full_path=False,\n",
    "    nonexist_ok=True,\n",
    "    recursive=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        full_path: True to return full paths to the dir contents\n",
    "        filter: function that takes in file name and returns True to include\n",
    "        nonexist_ok: True to return [] if the dir is non-existent, False to raise\n",
    "        sort: sort the file names by alphabetical\n",
    "        recursive: True to use os.walk to recursively list files. Note that `filter`\n",
    "            will be applied to the relative path string to the root dir.\n",
    "            e.g. filter will take \"a/data1.txt\" and \"a/b/data3.txt\" as input, instead of\n",
    "            just the base file names \"data1.txt\" and \"data3.txt\".\n",
    "            if False, will simply call os.listdir()\n",
    "    \"\"\"\n",
    "    assert not (filter_ext and filter), \"filter_ext and filter are mutually exclusive\"\n",
    "    dir_path = f_join(*fpaths)\n",
    "    if not os.path.exists(dir_path) and nonexist_ok:\n",
    "        return []\n",
    "    if recursive:\n",
    "        files = [\n",
    "            os.path.join(os.path.relpath(root, dir_path), file)\n",
    "            for root, _, files in os.walk(dir_path)\n",
    "            for file in files\n",
    "        ]\n",
    "    else:\n",
    "        files = os.listdir(dir_path)\n",
    "    if filter is not None:\n",
    "        files = [f for f in files if filter(f)]\n",
    "    elif filter_ext is not None:\n",
    "        files = [f for f in files if f.endswith(filter_ext)]\n",
    "    if sort:\n",
    "        files.sort()\n",
    "    if full_path:\n",
    "        return [os.path.join(dir_path, f) for f in files]\n",
    "    else:\n",
    "        return files\n",
    "\n",
    "\n",
    "def f_mkdir(*fpaths):\n",
    "    \"\"\"\n",
    "    Recursively creates all the subdirs\n",
    "    If exist, do nothing.\n",
    "    \"\"\"\n",
    "    fpath = f_join(*fpaths)\n",
    "    os.makedirs(fpath, exist_ok=True)\n",
    "    return fpath\n",
    "\n",
    "\n",
    "def f_mkdir_in_path(*fpaths):\n",
    "    \"\"\"\n",
    "    fpath is a file,\n",
    "    recursively creates all the parent dirs that lead to the file\n",
    "    If exist, do nothing.\n",
    "    \"\"\"\n",
    "    os.makedirs(get_dir(f_join(*fpaths)), exist_ok=True)\n",
    "\n",
    "\n",
    "def last_part_in_path(fpath):\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/3925096/how-to-get-only-the-last-part-of-a-path-in-python\n",
    "    \"\"\"\n",
    "    return os.path.basename(os.path.normpath(f_expand(fpath)))\n",
    "\n",
    "\n",
    "def is_abs_path(*fpath):\n",
    "    return os.path.isabs(f_join(*fpath))\n",
    "\n",
    "\n",
    "def is_relative_path(*fpath):\n",
    "    return not is_abs_path(f_join(*fpath))\n",
    "\n",
    "\n",
    "def f_time(*fpath):\n",
    "    \"File modification time\"\n",
    "    return str(os.path.getctime(f_join(*fpath)))\n",
    "\n",
    "\n",
    "def f_append_before_ext(fpath, suffix):\n",
    "    \"\"\"\n",
    "    Append a suffix to file name and retain its extension\n",
    "    \"\"\"\n",
    "    name, ext = f_ext(fpath)\n",
    "    return name + suffix + ext\n",
    "\n",
    "\n",
    "def f_add_ext(fpath, ext):\n",
    "    \"\"\"\n",
    "    Append an extension if not already there\n",
    "    Args:\n",
    "      ext: will add a preceding `.` if doesn't exist\n",
    "    \"\"\"\n",
    "    if not ext.startswith(\".\"):\n",
    "        ext = \".\" + ext\n",
    "    if fpath.endswith(ext):\n",
    "        return fpath\n",
    "    else:\n",
    "        return fpath + ext\n",
    "\n",
    "\n",
    "def f_has_ext(fpath, ext):\n",
    "    \"Test if file path is a text file\"\n",
    "    _, actual_ext = f_ext(fpath)\n",
    "    return actual_ext == \".\" + ext.lstrip(\".\")\n",
    "\n",
    "\n",
    "def f_glob(*fpath):\n",
    "    return glob.glob(f_join(*fpath), recursive=True)\n",
    "\n",
    "\n",
    "def f_remove(*fpath, verbose=False, dry_run=False):\n",
    "    \"\"\"\n",
    "    If exist, remove. Supports both dir and file. Supports glob wildcard.\n",
    "    \"\"\"\n",
    "    assert isinstance(verbose, bool)\n",
    "    fpath = f_join(fpath)\n",
    "    if dry_run:\n",
    "        print(\"Dry run, delete:\", fpath)\n",
    "        return\n",
    "    for f in glob.glob(fpath):\n",
    "        try:\n",
    "            shutil.rmtree(f)\n",
    "        except OSError as e:\n",
    "            if e.errno == errno.ENOTDIR:\n",
    "                try:\n",
    "                    os.remove(f)\n",
    "                except:  # final resort safeguard\n",
    "                    pass\n",
    "    if verbose:\n",
    "        print(f'Deleted \"{fpath}\"')\n",
    "\n",
    "\n",
    "def f_copy(fsrc, fdst, ignore=None, include=None, exists_ok=True, verbose=False):\n",
    "    \"\"\"\n",
    "    Supports both dir and file. Supports glob wildcard.\n",
    "    \"\"\"\n",
    "    fsrc, fdst = f_expand(fsrc), f_expand(fdst)\n",
    "    for f in glob.glob(fsrc):\n",
    "        try:\n",
    "            f_copytree(f, fdst, ignore=ignore, include=include, exist_ok=exists_ok)\n",
    "        except OSError as e:\n",
    "            if e.errno == errno.ENOTDIR:\n",
    "                shutil.copy(f, fdst)\n",
    "            else:\n",
    "                raise\n",
    "    if verbose:\n",
    "        print(f'Copied \"{fsrc}\" to \"{fdst}\"')\n",
    "\n",
    "\n",
    "def _f_copytree(\n",
    "    src,\n",
    "    dst,\n",
    "    symlinks=False,\n",
    "    ignore=None,\n",
    "    exist_ok=True,\n",
    "    copy_function=shutil.copy2,\n",
    "    ignore_dangling_symlinks=False,\n",
    "):\n",
    "    \"\"\"Copied from python standard lib shutil.copytree\n",
    "    except that we allow exist_ok\n",
    "    Use f_copytree as entry\n",
    "    \"\"\"\n",
    "    names = os.listdir(src)\n",
    "    if ignore is not None:\n",
    "        ignored_names = ignore(src, names)\n",
    "    else:\n",
    "        ignored_names = set()\n",
    "\n",
    "    os.makedirs(dst, exist_ok=exist_ok)\n",
    "    errors = []\n",
    "    for name in names:\n",
    "        if name in ignored_names:\n",
    "            continue\n",
    "        srcname = os.path.join(src, name)\n",
    "        dstname = os.path.join(dst, name)\n",
    "        try:\n",
    "            if os.path.islink(srcname):\n",
    "                linkto = os.readlink(srcname)\n",
    "                if symlinks:\n",
    "                    # We can't just leave it to `copy_function` because legacy\n",
    "                    # code with a custom `copy_function` may rely on copytree\n",
    "                    # doing the right thing.\n",
    "                    os.symlink(linkto, dstname)\n",
    "                    shutil.copystat(srcname, dstname, follow_symlinks=not symlinks)\n",
    "                else:\n",
    "                    # ignore dangling symlink if the flag is on\n",
    "                    if not os.path.exists(linkto) and ignore_dangling_symlinks:\n",
    "                        continue\n",
    "                    # otherwise let the copy occurs. copy2 will raise an error\n",
    "                    if os.path.isdir(srcname):\n",
    "                        _f_copytree(\n",
    "                            srcname, dstname, symlinks, ignore, exist_ok, copy_function\n",
    "                        )\n",
    "                    else:\n",
    "                        copy_function(srcname, dstname)\n",
    "            elif os.path.isdir(srcname):\n",
    "                _f_copytree(srcname, dstname, symlinks, ignore, exist_ok, copy_function)\n",
    "            else:\n",
    "                # Will raise a SpecialFileError for unsupported file types\n",
    "                copy_function(srcname, dstname)\n",
    "        # catch the Error from the recursive copytree so that we can\n",
    "        # continue with other files\n",
    "        except shutil.Error as err:\n",
    "            errors.extend(err.args[0])\n",
    "        except OSError as why:\n",
    "            errors.append((srcname, dstname, str(why)))\n",
    "    try:\n",
    "        shutil.copystat(src, dst)\n",
    "    except OSError as why:\n",
    "        # Copying file access times may fail on Windows\n",
    "        if getattr(why, \"winerror\", None) is None:\n",
    "            errors.append((src, dst, str(why)))\n",
    "    if errors:\n",
    "        raise shutil.Error(errors)\n",
    "    return dst\n",
    "\n",
    "\n",
    "def _include_patterns(*patterns):\n",
    "    \"\"\"Factory function that can be used with copytree() ignore parameter.\n",
    "\n",
    "    Arguments define a sequence of glob-style patterns\n",
    "    that are used to specify what files to NOT ignore.\n",
    "    Creates and returns a function that determines this for each directory\n",
    "    in the file hierarchy rooted at the source directory when used with\n",
    "    shutil.copytree().\n",
    "    \"\"\"\n",
    "\n",
    "    def _ignore_patterns(path, names):\n",
    "        keep = set(\n",
    "            name for pattern in patterns for name in fnmatch.filter(names, pattern)\n",
    "        )\n",
    "        ignore = set(\n",
    "            name\n",
    "            for name in names\n",
    "            if name not in keep and not os.path.isdir(os.path.join(path, name))\n",
    "        )\n",
    "        return ignore\n",
    "\n",
    "    return _ignore_patterns\n",
    "\n",
    "\n",
    "def f_copytree(fsrc, fdst, symlinks=False, ignore=None, include=None, exist_ok=True):\n",
    "    fsrc, fdst = f_expand(fsrc), f_expand(fdst)\n",
    "    assert (ignore is None) or (\n",
    "        include is None\n",
    "    ), \"ignore= and include= are mutually exclusive\"\n",
    "    if ignore:\n",
    "        ignore = shutil.ignore_patterns(*ignore)\n",
    "    elif include:\n",
    "        ignore = _include_patterns(*include)\n",
    "    _f_copytree(fsrc, fdst, ignore=ignore, symlinks=symlinks, exist_ok=exist_ok)\n",
    "\n",
    "\n",
    "def f_move(fsrc, fdst):\n",
    "    fsrc, fdst = f_expand(fsrc), f_expand(fdst)\n",
    "    for f in glob.glob(fsrc):\n",
    "        shutil.move(f, fdst)\n",
    "\n",
    "\n",
    "def f_split_path(fpath, normpath=True):\n",
    "    \"\"\"\n",
    "    Splits path into a list of its component folders\n",
    "\n",
    "    Args:\n",
    "        normpath: call os.path.normpath to remove redundant '/' and\n",
    "            up-level references like \"..\"\n",
    "    \"\"\"\n",
    "    if normpath:\n",
    "        fpath = os.path.normpath(fpath)\n",
    "    allparts = []\n",
    "    while 1:\n",
    "        parts = os.path.split(fpath)\n",
    "        if parts[0] == fpath:  # sentinel for absolute paths\n",
    "            allparts.insert(0, parts[0])\n",
    "            break\n",
    "        elif parts[1] == fpath:  # sentinel for relative paths\n",
    "            allparts.insert(0, parts[1])\n",
    "            break\n",
    "        else:\n",
    "            fpath = parts[0]\n",
    "            allparts.insert(0, parts[1])\n",
    "    return allparts\n",
    "\n",
    "\n",
    "def get_script_dir():\n",
    "    \"\"\"\n",
    "    Returns: the dir of current script\n",
    "    \"\"\"\n",
    "    return os.path.dirname(os.path.realpath(sys.argv[0]))\n",
    "\n",
    "\n",
    "def get_script_file_name():\n",
    "    \"\"\"\n",
    "    Returns: the dir of current script\n",
    "    \"\"\"\n",
    "    return os.path.basename(sys.argv[0])\n",
    "\n",
    "\n",
    "def get_script_self_path():\n",
    "    \"\"\"\n",
    "    Returns: the dir of current script\n",
    "    \"\"\"\n",
    "    return os.path.realpath(sys.argv[0])\n",
    "\n",
    "\n",
    "def get_parent_dir(location, abspath=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      location: current directory or file\n",
    "\n",
    "    Returns:\n",
    "        parent directory absolute or relative path\n",
    "    \"\"\"\n",
    "    _path = os.path.abspath if abspath else os.path.relpath\n",
    "    return _path(f_join(location, os.pardir))\n",
    "\n",
    "\n",
    "def md5_checksum(*fpath):\n",
    "    \"\"\"\n",
    "    File md5 signature\n",
    "    \"\"\"\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(f_join(*fpath), \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(65536), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()\n",
    "\n",
    "\n",
    "def create_tar(fsrc, output_tarball, include=None, ignore=None, compress_mode=\"gz\"):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        fsrc: source file or folder\n",
    "        output_tarball: output tar file name\n",
    "        compress_mode: \"gz\", \"bz2\", \"xz\" or \"\" (empty for uncompressed write)\n",
    "        include: include pattern, will trigger copy to temp directory\n",
    "        ignore: ignore pattern, will trigger copy to temp directory\n",
    "    \"\"\"\n",
    "    fsrc, output_tarball = f_expand(fsrc), f_expand(output_tarball)\n",
    "    assert compress_mode in [\"gz\", \"bz2\", \"xz\", \"\"]\n",
    "    src_base = os.path.basename(fsrc)\n",
    "\n",
    "    tempdir = None\n",
    "    if include or ignore:\n",
    "        tempdir = tempfile.mkdtemp()\n",
    "        tempdest = f_join(tempdir, src_base)\n",
    "        f_copy(fsrc, tempdest, include=include, ignore=ignore)\n",
    "        fsrc = tempdest\n",
    "\n",
    "    with tarfile.open(output_tarball, \"w:\" + compress_mode) as tar:\n",
    "        tar.add(fsrc, arcname=src_base)\n",
    "\n",
    "    if tempdir:\n",
    "        f_remove(tempdir)\n",
    "\n",
    "\n",
    "def extract_tar(source_tarball, output_dir=\".\", members=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        source_tarball: extract members from archive\n",
    "        output_dir: default to current working dir\n",
    "        members: must be a subset of the list returned by getmembers()\n",
    "    \"\"\"\n",
    "    source_tarball, output_dir = f_expand(source_tarball), f_expand(output_dir)\n",
    "    with tarfile.open(source_tarball, \"r:*\") as tar:\n",
    "        tar.extractall(output_dir, members=members)\n",
    "\n",
    "\n",
    "def move_with_backup(*fpath, suffix=\".bak\"):\n",
    "    \"\"\"\n",
    "    Ensures that a path is not occupied. If there is a file, rename it by\n",
    "    adding @suffix. Resursively backs up everything.\n",
    "\n",
    "    Args:\n",
    "        fpath: file path to clear\n",
    "        suffix: Add to backed up files (default: {'.bak'})\n",
    "    \"\"\"\n",
    "    fpath = str(f_join(*fpath))\n",
    "    if os.path.exists(fpath):\n",
    "        move_with_backup(fpath + suffix)\n",
    "        shutil.move(fpath, fpath + suffix)\n",
    "\n",
    "\n",
    "def insert_before_ext(name, insert):\n",
    "    \"\"\"\n",
    "    log.txt -> log.ep50.txt\n",
    "    \"\"\"\n",
    "    name, ext = os.path.splitext(name)\n",
    "    return name + insert + ext\n",
    "\n",
    "\n",
    "def timestamp_file_name(fname):\n",
    "    timestr = datetime.now().strftime(\"_%H-%M-%S_%m-%d-%y\")\n",
    "    return insert_before_ext(fname, timestr)\n",
    "\n",
    "\n",
    "def get_file_lock(*fpath, timeout: int = 15, logging_level=\"critical\"):\n",
    "    \"\"\"\n",
    "    NFS-safe filesystem-backed lock. `pip install flufl.lock`\n",
    "    https://flufllock.readthedocs.io/en/stable/apiref.html\n",
    "\n",
    "    Args:\n",
    "        fpath: should be a path on NFS so that every process can see it\n",
    "        timeout: seconds\n",
    "    \"\"\"\n",
    "    from flufl.lock import Lock\n",
    "\n",
    "    logging.getLogger(\"flufl.lock\").setLevel(logging_level.upper())\n",
    "    return Lock(f_join(*fpath), lifetime=timeout)\n",
    "\n",
    "\n",
    "def load_pickle(*fpaths):\n",
    "    with open(f_join(*fpaths), \"rb\") as fp:\n",
    "        return pickle.load(fp)\n",
    "\n",
    "\n",
    "def dump_pickle(data, *fpaths):\n",
    "    with open(f_join(*fpaths), \"wb\") as fp:\n",
    "        pickle.dump(data, fp)\n",
    "\n",
    "\n",
    "def load_text(*fpaths, by_lines=False):\n",
    "    with open(f_join(*fpaths), \"r\") as fp:\n",
    "        if by_lines:\n",
    "            return fp.readlines()\n",
    "        else:\n",
    "            return fp.read()\n",
    "\n",
    "\n",
    "def load_text_lines(*fpaths):\n",
    "    return load_text(*fpaths, by_lines=True)\n",
    "\n",
    "\n",
    "def dump_text(s, *fpaths):\n",
    "    with open(f_join(*fpaths), \"w\") as fp:\n",
    "        fp.write(s)\n",
    "\n",
    "\n",
    "def dump_text_lines(lines: list[str], *fpaths, add_newline=True):\n",
    "    with open(f_join(*fpaths), \"w\") as fp:\n",
    "        for line in lines:\n",
    "            print(line, file=fp, end=\"\\n\" if add_newline else \"\")\n",
    "\n",
    "class WithEmpty:\n",
    "    def __enter__(self):\n",
    "        pass\n",
    " \n",
    "    def __exit__(self, *args):\n",
    "        pass\n",
    "\n",
    "\n",
    "# aliases to be consistent with other load_* and dump_*\n",
    "pickle_load = load_pickle\n",
    "pickle_dump = dump_pickle\n",
    "text_load = load_text\n",
    "read_text = load_text\n",
    "read_text_lines = load_text_lines\n",
    "write_text = dump_text\n",
    "write_text_lines = dump_text_lines\n",
    "text_dump = dump_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "615596d7-3097-44f4-9683-7fc8af6b942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## json utils\n",
    "import json\n",
    "import re\n",
    "from typing import Any, Dict, Union\n",
    "# from .file_utils import f_join\n",
    "\n",
    "\n",
    "def json_load(*file_path, **kwargs):\n",
    "    file_path = f_join(file_path)\n",
    "    with open(file_path, \"r\") as fp:\n",
    "        return json.load(fp, **kwargs)\n",
    "\n",
    "\n",
    "def json_loads(string, **kwargs):\n",
    "    return json.loads(string, **kwargs)\n",
    "\n",
    "\n",
    "def json_dump(data, *file_path, **kwargs):\n",
    "    file_path = f_join(file_path)\n",
    "    with open(file_path, \"w\") as fp:\n",
    "        json.dump(data, fp, **kwargs)\n",
    "\n",
    "\n",
    "def json_dumps(data, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns: string\n",
    "    \"\"\"\n",
    "    return json.dumps(data, **kwargs)\n",
    "\n",
    "\n",
    "# ---------------- Aliases -----------------\n",
    "# add aliases where verb goes first, json_load -> load_json\n",
    "load_json = json_load\n",
    "loads_json = json_loads\n",
    "dump_json = json_dump\n",
    "dumps_json = json_dumps\n",
    "\n",
    "\n",
    "def extract_char_position(error_message: str) -> int:\n",
    "    \"\"\"Extract the character position from the JSONDecodeError message.\n",
    "    Args:\n",
    "        error_message (str): The error message from the JSONDecodeError\n",
    "          exception.\n",
    "    Returns:\n",
    "        int: The character position.\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    char_pattern = re.compile(r\"\\(char (\\d+)\\)\")\n",
    "    if match := char_pattern.search(error_message):\n",
    "        return int(match[1])\n",
    "    else:\n",
    "        raise ValueError(\"Character position not found in the error message.\")\n",
    "\n",
    "\n",
    "def add_quotes_to_property_names(json_string: str) -> str:\n",
    "    \"\"\"\n",
    "    Add quotes to property names in a JSON string.\n",
    "    Args:\n",
    "        json_string (str): The JSON string.\n",
    "    Returns:\n",
    "        str: The JSON string with quotes added to property names.\n",
    "    \"\"\"\n",
    "\n",
    "    def replace_func(match):\n",
    "        return f'\"{match.group(1)}\":'\n",
    "\n",
    "    property_name_pattern = re.compile(r\"(\\w+):\")\n",
    "    corrected_json_string = property_name_pattern.sub(replace_func, json_string)\n",
    "\n",
    "    try:\n",
    "        json.loads(corrected_json_string)\n",
    "        return corrected_json_string\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise e\n",
    "\n",
    "\n",
    "def balance_braces(json_string: str) -> str:\n",
    "    \"\"\"\n",
    "    Balance the braces in a JSON string.\n",
    "    Args:\n",
    "        json_string (str): The JSON string.\n",
    "    Returns:\n",
    "        str: The JSON string with braces balanced.\n",
    "    \"\"\"\n",
    "\n",
    "    open_braces_count = json_string.count(\"{\")\n",
    "    close_braces_count = json_string.count(\"}\")\n",
    "\n",
    "    while open_braces_count > close_braces_count:\n",
    "        json_string += \"}\"\n",
    "        close_braces_count += 1\n",
    "\n",
    "    while close_braces_count > open_braces_count:\n",
    "        json_string = json_string.rstrip(\"}\")\n",
    "        close_braces_count -= 1\n",
    "\n",
    "    try:\n",
    "        json.loads(json_string)\n",
    "        return json_string\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise e\n",
    "\n",
    "\n",
    "def fix_invalid_escape(json_str: str, error_message: str) -> str:\n",
    "    while error_message.startswith(\"Invalid \\\\escape\"):\n",
    "        bad_escape_location = extract_char_position(error_message)\n",
    "        json_str = json_str[:bad_escape_location] + json_str[bad_escape_location + 1 :]\n",
    "        try:\n",
    "            json.loads(json_str)\n",
    "            return json_str\n",
    "        except json.JSONDecodeError as e:\n",
    "            error_message = str(e)\n",
    "    return json_str\n",
    "\n",
    "\n",
    "def correct_json(json_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Correct common JSON errors.\n",
    "    Args:\n",
    "        json_str (str): The JSON string.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        json.loads(json_str)\n",
    "        return json_str\n",
    "    except json.JSONDecodeError as e:\n",
    "        error_message = str(e)\n",
    "        if error_message.startswith(\"Invalid \\\\escape\"):\n",
    "            json_str = fix_invalid_escape(json_str, error_message)\n",
    "        if error_message.startswith(\n",
    "            \"Expecting property name enclosed in double quotes\"\n",
    "        ):\n",
    "            json_str = add_quotes_to_property_names(json_str)\n",
    "            try:\n",
    "                json.loads(json_str)\n",
    "                return json_str\n",
    "            except json.JSONDecodeError as e:\n",
    "                error_message = str(e)\n",
    "        if balanced_str := balance_braces(json_str):\n",
    "            return balanced_str\n",
    "    return json_str\n",
    "\n",
    "\n",
    "def fix_and_parse_json(\n",
    "    json_str: str, try_to_fix_with_gpt: bool = True\n",
    ") -> Union[str, Dict[Any, Any]]:\n",
    "    \"\"\"Fix and parse JSON string\"\"\"\n",
    "    try:\n",
    "        json_str = json_str.replace(\"\\t\", \"\")\n",
    "        return json.loads(json_str)\n",
    "    except json.JSONDecodeError as _:  # noqa: F841\n",
    "        json_str = correct_json(json_str)\n",
    "        try:\n",
    "            return json.loads(json_str)\n",
    "        except json.JSONDecodeError as _:  # noqa: F841\n",
    "            pass\n",
    "    # Let's do something manually:\n",
    "    # sometimes GPT responds with something BEFORE the braces:\n",
    "    # \"I'm sorry, I don't understand. Please try again.\"\n",
    "    # {\"text\": \"I'm sorry, I don't understand. Please try again.\",\n",
    "    #  \"confidence\": 0.0}\n",
    "    # So let's try to find the first brace and then parse the rest\n",
    "    #  of the string\n",
    "    try:\n",
    "        brace_index = json_str.index(\"{\")\n",
    "        json_str = json_str[brace_index:]\n",
    "        last_brace_index = json_str.rindex(\"}\")\n",
    "        json_str = json_str[: last_brace_index + 1]\n",
    "        return json.loads(json_str)\n",
    "    except json.JSONDecodeError as e:  # noqa: F841\n",
    "        # if try_to_fix_with_gpt:\n",
    "        #     print(\n",
    "        #         \"Warning: Failed to parse AI output, attempting to fix.\"\n",
    "        #         \"\\n If you see this warning frequently, it's likely that\"\n",
    "        #         \" your prompt is confusing the AI. Try changing it up\"\n",
    "        #         \" slightly.\"\n",
    "        #     )\n",
    "        #     # Now try to fix this up using the ai_functions\n",
    "        #     ai_fixed_json = fix_json(json_str, JSON_SCHEMA)\n",
    "        #\n",
    "        #     if ai_fixed_json != \"failed\":\n",
    "        #         return json.loads(ai_fixed_json)\n",
    "        #     else:\n",
    "        #         # This allows the AI to react to the error message,\n",
    "        #         #   which usually results in it correcting its ways.\n",
    "        #         print(\"Failed to fix ai output, telling the AI.\")\n",
    "        #         return json_str\n",
    "        # else:\n",
    "        raise e\n",
    "\n",
    "\n",
    "# def fix_json(json_str: str, schema: str) -> str:\n",
    "#     \"\"\"Fix the given JSON string to make it parseable and fully complient with the provided schema.\"\"\"\n",
    "#\n",
    "#     # Try to fix the JSON using gpt:\n",
    "#     function_string = \"def fix_json(json_str: str, schema:str=None) -> str:\"\n",
    "#     args = [f\"'''{json_str}'''\", f\"'''{schema}'''\"]\n",
    "#     description_string = (\n",
    "#         \"Fixes the provided JSON string to make it parseable\"\n",
    "#         \" and fully complient with the provided schema.\\n If an object or\"\n",
    "#         \" field specified in the schema isn't contained within the correct\"\n",
    "#         \" JSON, it is ommited.\\n This function is brilliant at guessing\"\n",
    "#         \" when the format is incorrect.\"\n",
    "#     )\n",
    "#\n",
    "#     # If it doesn't already start with a \"`\", add one:\n",
    "#     if not json_str.startswith(\"`\"):\n",
    "#         json_str = \"```json\\n\" + json_str + \"\\n```\"\n",
    "#     result_string = call_ai_function(\n",
    "#         function_string, args, description_string, model=cfg.fast_llm_model\n",
    "#     )\n",
    "#     if cfg.debug:\n",
    "#         print(\"------------ JSON FIX ATTEMPT ---------------\")\n",
    "#         print(f\"Original JSON: {json_str}\")\n",
    "#         print(\"-----------\")\n",
    "#         print(f\"Fixed JSON: {result_string}\")\n",
    "#         print(\"----------- END OF FIX ATTEMPT ----------------\")\n",
    "#\n",
    "#     try:\n",
    "#         json.loads(result_string)  # just check the validity\n",
    "#         return result_string\n",
    "#     except:  # noqa: E722\n",
    "#         # Get the call stack:\n",
    "#         # import traceback\n",
    "#         # call_stack = traceback.format_exc()\n",
    "#         # print(f\"Failed to fix JSON: '{json_str}' \"+call_stack)\n",
    "#         return \"failed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fef6a968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sketch to finish: 24400\n"
     ]
    }
   ],
   "source": [
    "# from lego_prover.utils import load_json\n",
    "# load miniF2F tasks and resume from the checkpoint\n",
    "miniF2F_tasks = mp.Queue()\n",
    "problem_names = []\n",
    "if resume:\n",
    "    if os.path.exists(f\"{ckpt_dir}/curriculum/completed_tasks.json\"):\n",
    "        completed_tasks = load_json(\n",
    "            f\"{ckpt_dir}/curriculum/completed_tasks.json\")\n",
    "    if os.path.exists(f\"{ckpt_dir}/curriculum/failed_tasks.json\"):\n",
    "        failed_tasks =load_json(f\"{ckpt_dir}/curriculum/failed_tasks.json\")\n",
    "    print(\"Current progress: \", len(completed_tasks) + len(set(failed_tasks)))\n",
    "else:\n",
    "    completed_tasks = []\n",
    "    failed_tasks = []\n",
    "for name in os.listdir(f\"data/full_data/{data_split}\"):\n",
    "    path = os.path.join(f\"data/full_data/{data_split}\", name)\n",
    "    context = load_json(path)\n",
    "    problem_names.append((path, len(context[\"informal_proof\"])))\n",
    "problem_names = sorted(problem_names, key=lambda x: x[1])\n",
    "problem_names = [pn[0] for pn in problem_names]\n",
    "problem_names = problem_names * number_of_prover_attempts     # 10 * 20 = 200 sketch\n",
    "for pn in problem_names:\n",
    "    if pn in completed_tasks:\n",
    "        continue\n",
    "    if pn in failed_tasks:\n",
    "        failed_tasks.remove(pn)\n",
    "        continue\n",
    "    miniF2F_tasks.put(pn)\n",
    "print(f\"Sketch to finish: {miniF2F_tasks.qsize()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e115afef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup multiprocessing logger\n",
    "start_time = datetime.now(pytz.timezone(\n",
    "    'Asia/Shanghai')).strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "os.makedirs(f'logs/prover/{start_time}_logs', exist_ok=True)\n",
    "for rank in range(number_of_prover_processes):\n",
    "    logger = logging.getLogger(f'prover-{rank}')\n",
    "    handler = logging.FileHandler(\n",
    "        f\"logs/prover/{start_time}_logs/rank_{rank}.log\")\n",
    "    formatter = logging.Formatter(\n",
    "        \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    "    )\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "os.makedirs(f'logs/evolver/{start_time}_logs', exist_ok=True)\n",
    "for evolver_rank in range(number_of_evolver_processes):\n",
    "    evolver_rank += number_of_prover_processes\n",
    "    logger = logging.getLogger(f'evolver-{evolver_rank}')\n",
    "    handler = logging.FileHandler(\n",
    "        f\"logs/evolver/{start_time}_logs/rank_{evolver_rank}.log\")\n",
    "    formatter = logging.Formatter(\n",
    "        \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    "    )\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    logger.setLevel(logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cd4bae3-0779-4113-a777-2fbf9a043d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subprocessing\n",
    "\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import warnings\n",
    "from typing import List\n",
    "\n",
    "import psutil\n",
    "import subprocess\n",
    "import logging\n",
    "import threading\n",
    "\n",
    "# import lego_prover.utils as U\n",
    "\n",
    "\n",
    "class SubprocessMonitor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        commands: List[str],\n",
    "        name: str,\n",
    "        ready_match: str = r\".*\",\n",
    "        log_path: str = \"logs\",\n",
    "        callback_match: str = r\"^(?!x)x$\",  # regex that will never match\n",
    "        callback: callable = None,\n",
    "        finished_callback: callable = None,\n",
    "        cwd: str = os.path.expanduser(\"~\"),\n",
    "        server_port: int = -1,\n",
    "    ):\n",
    "        self.commands = commands\n",
    "        self.server_port = server_port\n",
    "        start_time = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "        self.name = name\n",
    "        if name == \"isabelle_server\":\n",
    "            os.makedirs(f'logs/{name}/{start_time}_logs', exist_ok=True)\n",
    "            self.logger = logging.getLogger(f'{name}-{server_port}')\n",
    "            handler = logging.FileHandler(f\"logs/{name}/{start_time}_logs/rank_{server_port}.log\")\n",
    "        else:\n",
    "            self.logger = logging.getLogger(name)\n",
    "            handler = logging.FileHandler(f_join(log_path, f\"{start_time}.log\"))\n",
    "        formatter = logging.Formatter(\n",
    "            \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    "        )\n",
    "        handler.setFormatter(formatter)\n",
    "        self.logger.addHandler(handler)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        self.process = None\n",
    "        self.ready_match = ready_match\n",
    "        self.ready_event = None\n",
    "        self.ready_line = None\n",
    "        self.callback_match = callback_match\n",
    "        self.callback = callback\n",
    "        self.finished_callback = finished_callback\n",
    "        self.thread = None\n",
    "        self.cwd = cwd\n",
    "\n",
    "    def _start(self):\n",
    "        self.logger.info(f\"Starting subprocess with commands: {self.commands}\")\n",
    "\n",
    "        self.process = psutil.Popen(\n",
    "            self.commands,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            stdin=subprocess.PIPE,\n",
    "            universal_newlines=True,\n",
    "            cwd=self.cwd\n",
    "        )\n",
    "        print(f\"Subprocess {self.name} started with PID {self.process.pid}.\")\n",
    "        for line in iter(self.process.stdout.readline, \"\"):\n",
    "            self.logger.info(line.strip())\n",
    "            if re.search(self.ready_match, line):\n",
    "                self.ready_line = line\n",
    "                self.logger.info(\"Subprocess is ready.\")\n",
    "                self.ready_event.set()\n",
    "                if \"chroma\" in self.name:\n",
    "                    break\n",
    "            if re.search(self.callback_match, line):\n",
    "                self.callback()\n",
    "        if not self.ready_event.is_set():\n",
    "            self.ready_event.set()\n",
    "            warnings.warn(f\"Subprocess {self.name} failed to start.\")\n",
    "        if self.finished_callback:\n",
    "            self.finished_callback()\n",
    "\n",
    "    def run(self):\n",
    "        self.ready_event = threading.Event()\n",
    "        self.ready_line = None\n",
    "        self.thread = threading.Thread(target=self._start)\n",
    "        self.thread.start()\n",
    "        self.ready_event.wait()\n",
    "\n",
    "    def stop(self):\n",
    "        self.logger.info(\"Stopping subprocess.\")\n",
    "        if self.process and self.process.is_running():\n",
    "            self.process.terminate()\n",
    "            self.process.wait()\n",
    "    \n",
    "    def terminate(self):\n",
    "        parent = psutil.Process(self.process.pid)\n",
    "        for child in parent.children(recursive=True):  # or parent.children() for recursive=False\n",
    "            child.kill()\n",
    "        parent.kill()\n",
    "\n",
    "    def run_action(self, inputs):\n",
    "        self.logger.info(f\"Input: {inputs}\")\n",
    "        self.process.stdin.write(inputs + '\\n')\n",
    "        self.process.stdin.flush()\n",
    "\n",
    "        for line in iter(self.process.stdout.readline, \"\"):\n",
    "            self.logger.info(line)\n",
    "            if line.startswith('{\"error'):\n",
    "                return json.loads(line)\n",
    "\n",
    "    @property\n",
    "    def is_running(self):\n",
    "        if self.process is None:\n",
    "            return False\n",
    "        return self.process.is_running()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0b17c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chroma\n",
    "import json\n",
    "import os\n",
    "# import lego_prover.utils as U\n",
    "# from .process_monitor import SubprocessMonitor\n",
    "import time\n",
    "\n",
    "\n",
    "class ChromaBridge:\n",
    "    def __init__(\n",
    "        self,\n",
    "        ckpt_path=\"ckpt\",\n",
    "        resume=False,\n",
    "        request_timeout=600,\n",
    "        log_path=\"./logs\",\n",
    "    ):\n",
    "        self.ckpt_path = ckpt_path\n",
    "        self.resume = \"True\" if resume else \"False\"\n",
    "        self.request_timeout = request_timeout\n",
    "        self.log_path = log_path\n",
    "        self.chroma_server = self.get_chroma_process()\n",
    "        self.chroma_server.run()\n",
    "        \n",
    "        # wait for isabelle server to run\n",
    "        time.sleep(3)\n",
    "\n",
    "    def get_chroma_process(self):\n",
    "        f_mkdir(self.log_path, \"chromadb\")\n",
    "        return SubprocessMonitor(\n",
    "            commands=[\n",
    "                \"python\",\n",
    "                \"chroma_worker.py\",\n",
    "                \"--ckpt_path\",\n",
    "                self.ckpt_path,\n",
    "                \"--resume\",\n",
    "                self.resume\n",
    "            ],\n",
    "            name=\"chroma_worker\",\n",
    "            ready_match=r\"Chroma worker is ready.\",\n",
    "            log_path=f_join(self.log_path, \"chromadb\"),\n",
    "            cwd=os.path.abspath(\"lego_prover/env/\")\n",
    "        )\n",
    "\n",
    "    def run_cmd(self, cmd):\n",
    "        cmd = json.dumps(cmd)\n",
    "        return self.chroma_server.run_action(cmd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2c3e2f7-5a8c-4650-817c-ca396335cf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from __future__ import annotations\n",
    "import random\n",
    "import time\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.embeddings.openai import embed_with_retry\n",
    "from langchain.chat_models.openai import _create_retry_decorator\n",
    "from langchain.schema import LLMResult, AIMessage, HumanMessage, SystemMessage, ChatGeneration\n",
    "# from openai_key import *\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4be5cd6a-5118-4305-b55a-ab0f2a9f8a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from typing import List, Optional, Any\n",
    "\n",
    "import numpy as np\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "# from ananke.llm.thudm import ZhiPu\n",
    "from ananke.llm.azure import Azure\n",
    "from ananke.llm.ernie import Ernie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffe66597",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class LLMMixture:\n",
    "    def __init__(self, model_name, temperature, request_timeout) -> None:\n",
    "        self.encoder = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "        self.request_timeout = request_timeout\n",
    "\n",
    "        if 'gpt-3.5' in self.model_name:\n",
    "            self.azure_openai_model = Azure(chat_model_name=\"Ananke3-1106-US-WEST\")\n",
    "        elif 'gpt-4' in self.model_name:\n",
    "            self.azure_openai_model = Azure(chat_model_name=\"Ananke4-1106-US-WEST\")\n",
    "        else:\n",
    "            self.azure_openai_model = Azure(chat_model_name=\"Ananke3-1106-US-WEST\")\n",
    "    \n",
    "    def query(self, langchain_msgs, llm_type=\"short\", n=1, temperature=None, max_tokens=None):\n",
    "        success = False\n",
    "        max_retry = 50\n",
    "        messages = []\n",
    "        for msg in langchain_msgs:\n",
    "            if isinstance(msg, SystemMessage):\n",
    "                messages.append({\"role\": \"system\", \"content\": msg.content})\n",
    "            if isinstance(msg, HumanMessage):\n",
    "                messages.append({\"role\": \"user\", \"content\": msg.content})\n",
    "        while max_retry > 0:\n",
    "            try:\n",
    "                if temperature is None:\n",
    "                    temperature = self.temperature\n",
    "                response = self.azure_openai_model.client.chat.completions.create(\n",
    "                            model=self.azure_openai_model.chat_model, messages=messages,\n",
    "                            temperature=temperature\n",
    "                            )\n",
    "                # response = openai.ChatCompletion.create(\n",
    "                #     model=llm_model,\n",
    "                #     messages=messages,\n",
    "                #     temperature=temperature,\n",
    "                #     n=n,\n",
    "                #     api_key=api_key[0],\n",
    "                #     organization=api_key[1],\n",
    "                #     max_tokens=max_tokens,\n",
    "                # )\n",
    "                # print(\"ckpt in 2\")\n",
    "            except openai.error.RateLimitError:\n",
    "                print(\".\", end=\"\", flush=True)\n",
    "                time.sleep(0.1)\n",
    "            except openai.error.APIConnectionError as e:\n",
    "                time.sleep(random.randint(1,30))\n",
    "                print(f\"Openai Connection{e}\")\n",
    "                max_retry -= 1\n",
    "            except openai.error.APIError as e:\n",
    "                time.sleep(random.randint(1,30))\n",
    "                if 'Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\"' in str(e):\n",
    "                    print(\"-\", end=\"\", flush=True)\n",
    "                else:\n",
    "                    print(f\"APIError了: {e}\")\n",
    "                max_retry -= 1\n",
    "            except Exception as e:\n",
    "                time.sleep(random.randint(1,30))\n",
    "                print(f\"Exception 了:{e}\")\n",
    "                max_retry -= 1\n",
    "            else:\n",
    "                success = True\n",
    "                break\n",
    "        if success:\n",
    "            if n == 1:\n",
    "                res = response.get(\"choices\")[0][\"message\"][\"content\"]\n",
    "                return res\n",
    "            else:\n",
    "                res = []\n",
    "                for ix in range(n):\n",
    "                    res.append(response.get(\"choices\")[ix][\"message\"][\"content\"])\n",
    "                return res\n",
    "        else:\n",
    "            return \"\"\n",
    "\n",
    "    def __call__(self, messages, temperature=None, max_tokens=1024, n=1) -> Any:\n",
    "        word_count = 0\n",
    "        for msg in messages:\n",
    "            word_count += len(self.encoder.encode(msg.content))\n",
    "        if \"gpt-4\" in self.model_name:\n",
    "            if word_count < 7000:\n",
    "                results = self.query(messages, \"short\", temperature=temperature, n=n)\n",
    "            else:\n",
    "                assert False, f\"query too long, with {word_count} token in total\" \n",
    "        else:\n",
    "            if word_count < 3500:\n",
    "                results = self.query(messages, \"short\", temperature=temperature, n=n)\n",
    "            elif word_count < (16385 - 2100):\n",
    "                results = self.query(messages, \"long\",  temperature=temperature, max_tokens=max_tokens, n=n)\n",
    "            else:\n",
    "                assert False, f\"query too long, with {word_count} token in total\" \n",
    "        \n",
    "        if n==1:\n",
    "            return AIMessage(content=results)\n",
    "        else:\n",
    "            ret_messages = []\n",
    "            for res in results:\n",
    "                ret_messages.append(AIMessage(content=res))\n",
    "            return ret_messages\n",
    "            \n",
    "    \n",
    "    def generate(self, batch_message, slow_mode=False, temperature=None, max_tokens=1024):\n",
    "        if slow_mode is False:\n",
    "            # print(\"ckpt 1\")\n",
    "            n = len(batch_message)\n",
    "            word_count = 0\n",
    "            messages = batch_message[0]\n",
    "            for msg in messages:\n",
    "                word_count += len(self.encoder.encode(msg.content))\n",
    "            # print(f\"ckpt 2 {word_count}\")\n",
    "            if \"gpt-4\" in self.model_name:\n",
    "                if word_count < 7000:\n",
    "                    results = self.query(messages, \"short\", n=n, temperature=temperature, max_tokens=max_tokens)\n",
    "                else:\n",
    "                    assert False, f\"query too long, with {word_count} token in total\" \n",
    "            else:\n",
    "                if word_count < 3500:\n",
    "                    results = self.query(messages, \"short\", n=n, temperature=temperature, max_tokens=max_tokens)\n",
    "                elif word_count < 15000:\n",
    "                    results = self.query(messages, \"long\", n=n, temperature=temperature, max_tokens=max_tokens)\n",
    "                else:\n",
    "                    assert False, f\"query too long, with {word_count} token in total\" \n",
    "            generations = []\n",
    "            for res in results:\n",
    "                generations.append([ChatGeneration(message=AIMessage(content=res))])\n",
    "            # print(f\"Here successful with {len(results)}\")\n",
    "            return LLMResult(generations=generations)\n",
    "        else:\n",
    "            results = []\n",
    "            for messages in batch_message:\n",
    "                word_count = 0\n",
    "                messages = batch_message[0]\n",
    "                for msg in messages:\n",
    "                    word_count += len(self.encoder.encode(msg.content))\n",
    "                if word_count < 7000:\n",
    "                    res = self.query(messages, \"short\")\n",
    "                else:\n",
    "                    res = self.query(messages, \"long\")\n",
    "                results.append(res)\n",
    "            generations = []\n",
    "            for res in results:\n",
    "                generations.append([ChatGeneration(text=res)])\n",
    "            return LLMResult(generations=generations)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c81287f-6156-45d9-98b5-ca31a37b59ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "\n",
    "# import lego_prover.utils as U\n",
    "from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# from lego_prover.prompts import load_prompt\n",
    "\n",
    "# from lego_prover.utils.langchain_utils import LLMMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78869803-903a-4a55-8328-317863460fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "# import lego_prover.utils as U \n",
    "\n",
    "\n",
    "def load_prompt(prompt):\n",
    "    package_path = pkg_resources.resource_filename(\"lego_prover\", \"\")\n",
    "    return load_text(f\"{package_path}/prompts/{prompt}.txt\")\n",
    "\n",
    "def load_context(problem_path):\n",
    "    return load_json(problem_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00b1f3a8-d8c8-47c9-b946-5340f49cc844",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ActionAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        logger=None,\n",
    "        model_name=\"gpt-3.5-turbo\",\n",
    "        temperature=0,\n",
    "        request_timeout=120,\n",
    "        ckpt_dir=\"ckpt\",\n",
    "    ):\n",
    "        self.logger = logger\n",
    "        self.ckpt_dir = ckpt_dir\n",
    "        f_mkdir(f\"{ckpt_dir}/action\")\n",
    "        self.llm = LLMMixture(\n",
    "            model_name=model_name,\n",
    "            temperature=temperature,\n",
    "            request_timeout=request_timeout,\n",
    "        )\n",
    "\n",
    "        # load decomposer examples:\n",
    "        self.decomposer_examples = {}\n",
    "        for file in os.listdir(\"data/decomposer_examples\"):\n",
    "            with open(os.path.join(\"data/decomposer_examples\", file), \"r\") as f:\n",
    "                text = f.read()\n",
    "            self.decomposer_examples[file[:-4]] = text\n",
    "        \n",
    "        self.formalizer_examples = {}\n",
    "        for file in os.listdir(\"data/formalizer_examples\"):\n",
    "            with open(os.path.join(\"data/formalizer_examples\", file), \"r\") as f:\n",
    "                text = f.read()\n",
    "            self.formalizer_examples[file[:-4]] = text\n",
    "    \n",
    "    def retrieved_example_skills(self, retrieved_skills):\n",
    "        random.shuffle(retrieved_skills)\n",
    "        prompt_examples = []\n",
    "        for ix, skills in enumerate(retrieved_skills):\n",
    "            skill_code = skills[\"code\"]\n",
    "            prompt_example = f\"\"\"###### useful skill {ix+1}: ######\n",
    "```isabelle\n",
    "{skill_code}\n",
    "```\n",
    "\"\"\"\n",
    "            prompt_examples.append(prompt_example)\n",
    "        \n",
    "        example_programmes = \"\\n\\n\".join(prompt_examples)\n",
    "        return example_programmes\n",
    "    \n",
    "    def decomposer(self, context):\n",
    "        system_prompt_template = load_prompt(\"decomposer\")\n",
    "        system_message = SystemMessage(content=system_prompt_template)\n",
    "\n",
    "        human_prompt_template = load_prompt(\"decomposer_human\")\n",
    "        human_prompt_template = HumanMessagePromptTemplate.from_template(human_prompt_template)\n",
    "\n",
    "        # post-process in-context-learning examples\n",
    "        decomposer_examples = copy(self.decomposer_examples)\n",
    "        if context[\"problem_name\"] in decomposer_examples:\n",
    "            decomposer_examples.pop(context[\"problem_name\"])\n",
    "        icl_examples = random.sample(list(decomposer_examples.values()), 3)\n",
    "        icl_examples = \"\\n\\n####################\\n\\n\".join(icl_examples)\n",
    "\n",
    "        context[\"informal_statement\"] = context[\"informal_statement\"].replace(\"\\n\", ' ').strip()\n",
    "        context[\"informal_proof\"] = context[\"informal_proof\"].replace(\"\\n\", \" \").strip()\n",
    "\n",
    "        human_message = human_prompt_template.format(\n",
    "            examples=icl_examples,\n",
    "            informal_statement=context[\"informal_statement\"],\n",
    "            informal_proof=context[\"informal_proof\"],\n",
    "            formal_statement=context[\"formal_statement\"],\n",
    "        )\n",
    "\n",
    "        conversation = {\n",
    "            \"sys0\":  system_message.content,\n",
    "            \"human0\": human_message.content,\n",
    "        }\n",
    "\n",
    "        self.logger.info(\n",
    "            f\"****decomposer system message****\\n{system_message.content}\"\n",
    "        )\n",
    "\n",
    "        self.logger.info(\n",
    "            f\"****decomposer human message****\\n{human_message.content}\"\n",
    "        )\n",
    "\n",
    "        n_retry = 3\n",
    "        informal_proof = context[\"informal_proof\"]\n",
    "        skill_requests = []\n",
    "        while n_retry > 0:\n",
    "            try:\n",
    "                ai_message = self.llm([system_message, human_message], temperature=0)\n",
    "                self.logger.info(\n",
    "                    f\"****decomposer ai message****\\n{ai_message.content}\"\n",
    "                )\n",
    "                conversation[f\"ai{3-n_retry}\"] = ai_message.content\n",
    "                message = ai_message.content\n",
    "                if \"####################\" in message:\n",
    "                    message = message[:message.index(\"####################\")]\n",
    "                # Extracting Error Analysis content\n",
    "                informal_proof = re.search(r'## Structured informal proof\\n(.*?)\\n\\n#', message, re.DOTALL).group(1).strip()\n",
    "\n",
    "                # Extracting each skill request's name and its content\n",
    "                skill_requests = re.findall(r\"```isabelle\\n(.*?)\\n```\", message, re.DOTALL)\n",
    "                break\n",
    "            except AssertionError as e:\n",
    "                if \"query too long\" in str(e):\n",
    "                    self.logger.warn(str(e))\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                self.logger.info(f\"Error occur in decomposer: {str(e)}\")\n",
    "                n_retry -= 1\n",
    "                examples = random.sample(list(decomposer_examples.values()), 3)\n",
    "                examples = \"\\n\\n####################\\n\\n\".join(examples)\n",
    "                human_message = human_prompt_template.format(\n",
    "                    examples=examples,\n",
    "                    informal_statement=context[\"informal_statement\"],\n",
    "                    informal_proof=context[\"informal_proof\"],\n",
    "                    formal_statement=context[\"formal_statement\"],\n",
    "                )\n",
    "                time.sleep(5)\n",
    "        ret_request = []\n",
    "        for skill in skill_requests:\n",
    "            if \"N/A\" in skill:\n",
    "                continue\n",
    "            ret_request.append(skill)\n",
    "\n",
    "        if len(ret_request) > 5:\n",
    "            self.logger.info(f\"skill request more than 5, with len {len(ret_request)}\")\n",
    "            ret_request = random.sample(ret_request, 5)\n",
    "\n",
    "        return informal_proof, ret_request, conversation\n",
    "\n",
    "    def critic(self, context, code_last_round=None, error_last_round=None):\n",
    "        system_prompt_template = load_prompt(\"critic_request\")\n",
    "        system_prompt_template = SystemMessagePromptTemplate.from_template(system_prompt_template)\n",
    "        system_message = system_prompt_template.format(examples=\"\")\n",
    "\n",
    "        human_prompt_template = load_prompt(\"critic_request_human\")\n",
    "        human_prompt_template = HumanMessagePromptTemplate.from_template(human_prompt_template)\n",
    "\n",
    "        if code_last_round is None:\n",
    "            code_last_round = \"No code from last round...\"\n",
    "        else:\n",
    "            code_last_round = code_last_round.split('\\n')\n",
    "            new_code = []\n",
    "            for ix, line in enumerate(code_last_round):\n",
    "                line = f\"#{ix+1} \" + line\n",
    "                new_code.append(line)\n",
    "            code_last_round = \"\\n\".join(new_code)\n",
    "        \n",
    "        if error_last_round is None:\n",
    "            error_last_round = \"No error from last round...\"\n",
    "\n",
    "        human_message = human_prompt_template.format(\n",
    "            code=code_last_round,\n",
    "            error=error_last_round,\n",
    "        )\n",
    "\n",
    "        # self.logger.info(\n",
    "        #     f\"****critic agent system message****\\n{system_message.content}\"\n",
    "        # )\n",
    "\n",
    "        self.logger.info(\n",
    "            f\"****critic agent human message****\\n{human_message.content}\"\n",
    "        )\n",
    "\n",
    "        n_retry = 3\n",
    "        error_analysis = \"No error analysis...\"\n",
    "        skill_requests = []\n",
    "        while n_retry > 0:\n",
    "            try:\n",
    "                ai_message = self.llm([system_message, human_message])\n",
    "                self.logger.info(\n",
    "                    f\"****critic agent ai message****\\n{ai_message.content}\"\n",
    "                )\n",
    "                message = ai_message.content\n",
    "                # Extracting Error Analysis content\n",
    "                error_analysis = re.search(r'# Error analysis:\\n(.*?)\\n\\n#', message, re.DOTALL).group(1).strip()\n",
    "\n",
    "                # Extracting each skill request's name and its content\n",
    "                skill_requests = re.findall(r'## Skill \\d+: ([\\w_]+)\\n```isabelle\\n(.*?)\\n```', message, re.DOTALL)\n",
    "                break\n",
    "            except AssertionError as e:\n",
    "                if \"query too long\" in str(e):\n",
    "                    self.logger.warn(str(e))\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                self.logger.info(f\"Error occur in auto_formal_pre: {str(e)}\")\n",
    "                n_retry -= 1\n",
    "                time.sleep(5)\n",
    "\n",
    "        return error_analysis, skill_requests\n",
    "    \n",
    "    def render_formalizer_system_message(self):\n",
    "        system_template = load_prompt(\"formalizer\")\n",
    "        return SystemMessage(content=system_template)\n",
    "    \n",
    "    def render_formalizer_human_message(\n",
    "        self,\n",
    "        skills,\n",
    "        context,\n",
    "        informal_proof=None,\n",
    "        n_example=3,\n",
    "    ) -> HumanMessage:\n",
    "        human_prompt_template = load_prompt(\"formalizer_human\")\n",
    "        human_prompt_template = HumanMessagePromptTemplate.from_template(human_prompt_template)\n",
    "\n",
    "        formalizer_examples = copy(self.formalizer_examples)\n",
    "        if context[\"problem_name\"] in formalizer_examples:\n",
    "            formalizer_examples.pop(context[\"problem_name\"])\n",
    "\n",
    "        examples = random.sample(list(formalizer_examples.values()), n_example)\n",
    "        examples = \"\\n\\n####################\\n\\n\".join(examples)\n",
    "        context[\"informal_statement\"] = context[\"informal_statement\"].replace(\"\\n\", ' ').strip()\n",
    "        context[\"informal_proof\"] = context[\"informal_proof\"].replace(\"\\n\", \" \").strip()\n",
    "\n",
    "        skills = self.retrieved_example_skills(skills)\n",
    "        \n",
    "        human_message = human_prompt_template.format(\n",
    "            skill_examples = skills,\n",
    "            examples=examples,\n",
    "            informal_statement=context[\"informal_statement\"],\n",
    "            informal_proof=context[\"informal_proof\"] if informal_proof is None else informal_proof,\n",
    "            formal_statement=context[\"formal_statement\"],\n",
    "        )\n",
    "\n",
    "        return human_message\n",
    "\n",
    "\n",
    "    def render_human_message(\n",
    "        self, \n",
    "        context, \n",
    "        code=None,\n",
    "        error=None,\n",
    "        error_analysis=None,\n",
    "        informal_proof=None,\n",
    "    ) -> HumanMessage:\n",
    "        human_prompt_template = load_prompt(\"auto_formal2_human\")\n",
    "        human_prompt_template = HumanMessagePromptTemplate.from_template(human_prompt_template)\n",
    "\n",
    "        if code is None:\n",
    "            code = \"No code from last round...\"\n",
    "        else:\n",
    "            code = code.split('\\n')\n",
    "            new_code = []\n",
    "            for ix, line in enumerate(code):\n",
    "                line = f\"#{ix+1} \" + line\n",
    "                new_code.append(line)\n",
    "            code = \"\\n\".join(new_code)\n",
    "        \n",
    "        if error is None:\n",
    "            error = \"No error from last round...\"\n",
    "        if error_analysis is None:\n",
    "            error_analysis = \"No analysis...\"\n",
    "\n",
    "        human_message = human_prompt_template.format(\n",
    "            informal_statement=context[\"informal_statement\"],\n",
    "            informal_proof=context[\"informal_proof\"] if informal_proof is None else informal_proof,\n",
    "            formal_statement=context[\"formal_statement\"],\n",
    "            code_last_round=code,\n",
    "            error_last_round=error,\n",
    "            error_analysis=error_analysis,\n",
    "        )\n",
    "\n",
    "        return human_message\n",
    "\n",
    "    def process_ai_message(self, message, context):\n",
    "        assert isinstance(message, AIMessage)\n",
    "\n",
    "        retry = 3\n",
    "        error = None\n",
    "        while retry > 0:\n",
    "            try:\n",
    "                code_pattern = re.compile(r\"```(?:[i|I]sabelle)(.*?)```\", re.DOTALL)\n",
    "                text = message.content[message.content.index(\"# Formalized Code\"):]\n",
    "                code = \"\\n\".join(code_pattern.findall(text)).strip()\n",
    "                return code\n",
    "            except Exception as e:\n",
    "                retry -= 1\n",
    "                error = e\n",
    "                time.sleep(1)\n",
    "        self.logger.info(f\"Error parsing action response (before program execution): {error}\")\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee7293f9-ffcf-4f84-bb78-f6530801e916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "# import lego_prover.utils as U\n",
    "# from lego_prover.env.chromas import ChromaBridge\n",
    "\n",
    "# from lego_prover.utils.langchain_utils import LLMMixture\n",
    "\n",
    "from difflib import SequenceMatcher, get_close_matches\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "\n",
    "class SkillManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        rank = None,\n",
    "        logger = None,\n",
    "        ckpt_dir=\"ckpt\",\n",
    "        skill_manager_lock=WithEmpty(),\n",
    "        chroma_bridge: ChromaBridge  = None\n",
    "    ):\n",
    "        self.rank = rank\n",
    "        self.logger = logger\n",
    "        self.skill_manager_lock = skill_manager_lock\n",
    "        self.chroma_bridge = chroma_bridge\n",
    "        f_mkdir(f\"{ckpt_dir}/skill/code\")\n",
    "        f_mkdir(f\"{ckpt_dir}/skill/history_problem\")\n",
    "        f_mkdir(f\"{ckpt_dir}/skill/requests\")\n",
    "        f_mkdir(f\"{ckpt_dir}/skill/description\")\n",
    "        f_mkdir(f\"{ckpt_dir}/skill/vectordb\")\n",
    "        self.ckpt_dir = ckpt_dir\n",
    "        self.encoder = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "        with self.skill_manager_lock:\n",
    "            self.sync_checkpoint()\n",
    "    \n",
    "    def sync_checkpoint(self):\n",
    "        if os.path.exists(f\"{self.ckpt_dir}/skill/skills.json\"):\n",
    "            self.skills = load_json(f\"{self.ckpt_dir}/skill/skills.json\")\n",
    "        else:\n",
    "            self.skills = {}\n",
    "        if os.path.exists(f\"{self.ckpt_dir}/skill/codes.json\"):\n",
    "            self.codes = load_json(f\"{self.ckpt_dir}/skill/codes.json\")\n",
    "        else:\n",
    "            self.codes = {}\n",
    "        if os.path.exists(f\"{self.ckpt_dir}/skill/skill_request.json\"):\n",
    "            self.skill_requests = load_json(f\"{self.ckpt_dir}/skill/skill_request.json\")\n",
    "        else:\n",
    "            self.skill_requests = {}\n",
    "    \n",
    "    def add_new_problem(self, problem_name, formal_statement):\n",
    "        data = (\"problem_add_text\", {\n",
    "                \"add_text\": formal_statement,\n",
    "                \"problem_name\": problem_name,\n",
    "        })\n",
    "        output = self.chroma_bridge.run_cmd(data)\n",
    "        assert output[\"error\"] is None, \"error is not None\"\n",
    "        print(output[\"output\"])\n",
    "\n",
    "    def add_new_request(self, problem_name, formal_statement, init_update_count=0):\n",
    "        with self.skill_manager_lock:\n",
    "            self.sync_checkpoint()\n",
    "\n",
    "        exists_formal_statements = [value['formal_statement'] for value in self.skill_requests.values()]\n",
    "        if len(get_close_matches(formal_statement, exists_formal_statements, n=1, cutoff=0.85)) != 0:\n",
    "            return\n",
    "\n",
    "        with self.skill_manager_lock:\n",
    "            self.sync_checkpoint()\n",
    "            request_name = f\"request_{len(self.skill_requests)}\"\n",
    "            self.skill_requests[request_name] = {\n",
    "                \"request_name\": request_name,\n",
    "                \"problem_name\": problem_name,\n",
    "                \"formal_statement\": formal_statement,\n",
    "                \"update_count\": init_update_count,\n",
    "            }\n",
    "            \n",
    "\n",
    "            data = (\"request_add_text\", {\n",
    "                \"add_text\": formal_statement,\n",
    "                \"request_name\": request_name,\n",
    "            })\n",
    "            \n",
    "            assert self.chroma_bridge is not None\n",
    "            output = self.chroma_bridge.run_cmd(data)\n",
    "            if output[\"error\"] is None:\n",
    "                # print(\"There are\",  output[\"output\"], \"code\")\n",
    "                assert output[\"output\"] == len(\n",
    "                    self.skill_requests\n",
    "                ), (\"requestdb is not synced with skill_request.json, \"\n",
    "                    f\"there are {output['output']} in requestdb but {len(self.skill_requests)} in skill_request.json\")\n",
    "            \n",
    "            dump_text(\n",
    "                formal_statement, f\"{self.ckpt_dir}/skill/requests/{request_name}.thy\"\n",
    "            )\n",
    "            dump_json(self.skill_requests, f\"{self.ckpt_dir}/skill/skill_request.json\")\n",
    "            self.logger.info(f\"Added skill, marker:\\n ```isabelle\\n{formal_statement}```\\n\")      \n",
    "\n",
    "    def add_new_skill(self, skill_name, description, marker, full_code, origin=\"\", init_update_count=0):\n",
    "        with self.skill_manager_lock:\n",
    "            self.sync_checkpoint()\n",
    "\n",
    "        exists_markers = [value['marker'] for value in self.skills.values()]\n",
    "        if len(self.encoder.encode(marker)) > 650:\n",
    "            return\n",
    "        if len(get_close_matches(marker, exists_markers, n=1, cutoff=0.85)) != 0:\n",
    "            return\n",
    "\n",
    "        if not bool(re.match(\"^[a-zA-Z0-9_']+$\", skill_name)):\n",
    "            skill_name = f\"skill_{len(self.skills)}\"\n",
    "\n",
    "        skill_name = skill_name.lower().strip().replace(\" \", \"_\")\n",
    "        if skill_name in self.skills:\n",
    "            i = 2\n",
    "            while f\"{skill_name}V{i}\" in self.skills:\n",
    "                i += 1\n",
    "            skill_name = f\"{skill_name}V{i}\"\n",
    "\n",
    "        with self.skill_manager_lock:\n",
    "            self.sync_checkpoint()\n",
    "\n",
    "            self.skills[skill_name] = {\n",
    "                \"skill_name\": skill_name,\n",
    "                \"marker\": marker,\n",
    "                \"description\": description,\n",
    "                \"full_code\": full_code,\n",
    "                \"origin\": origin,\n",
    "                \"update_count\": init_update_count,\n",
    "            }\n",
    "\n",
    "            # add_text = f\"code: {marker}, skill: {skill_name}, description: {description},\"\n",
    "            add_text = marker\n",
    "            \n",
    "            # use chroma bridge to add skill to the chromadb\n",
    "            assert self.chroma_bridge is not None\n",
    "            data = (\"skill_add_text\",{\n",
    "                \"skill_name\": skill_name,\n",
    "                \"add_text\": add_text,\n",
    "            })\n",
    "            output = self.chroma_bridge.run_cmd(data)\n",
    "            if output[\"error\"] is None:\n",
    "                assert output[\"output\"] == len(\n",
    "                    self.skills\n",
    "                ), (\"vectordb is not synced with skill.json\"\n",
    "                    f\"there are {output['output']} in skilldb but {len(self.skills)} in skills.json\")\n",
    "            \n",
    "            dump_text(\n",
    "                marker, f\"{self.ckpt_dir}/skill/code/{skill_name}.thy\"\n",
    "            )\n",
    "            dump_text(\n",
    "                description,\n",
    "                f\"{self.ckpt_dir}/skill/description/{skill_name}.txt\",\n",
    "            )\n",
    "            dump_json(self.skills, f\"{self.ckpt_dir}/skill/skills.json\")\n",
    "            self.logger.info(f\"Added skill, marker:\\n ```isabelle\\n{marker}```\\nfull_code:\\nisabelle\\n{full_code}\\n\")\n",
    "\n",
    "    def update_count(self, skill_name):\n",
    "        with self.skill_manager_lock:\n",
    "            self.sync_checkpoint()\n",
    "            self.skills[skill_name][\"update_count\"] += 1\n",
    "            dump_json(self.skills, f\"{self.ckpt_dir}/skill/skills.json\")\n",
    "    \n",
    "    def update_count_request(self, request_name):\n",
    "        with self.skill_manager_lock:\n",
    "            self.sync_checkpoint()\n",
    "            self.skill_requests[request_name][\"update_count\"] += 1\n",
    "            dump_json(self.skill_requests, f\"{self.ckpt_dir}/skill/skill_request.json\")\n",
    "\n",
    "    def retrieve_skills(self, query, k):\n",
    "        ret_skill = []\n",
    "        k = min(len(self.skills), k)\n",
    "        if k != 0:\n",
    "            self.logger.info(f\"Skill Manager retrieving for {k} skills\")\n",
    "            with self.skill_manager_lock:\n",
    "                # query = f\"informal statement: {context['informal_statement']}, informal proof: {context['informal_proof']}, formal_statement: {context['formal_statement']}\"\n",
    "                data = (\"skill_query\", {\"query\": query, \"k\": k})\n",
    "                outputs = self.chroma_bridge.run_cmd(data)\n",
    "                ret_skill_name = []\n",
    "                if outputs[\"error\"] is None:\n",
    "                    ret_skill_name = outputs[\"output\"]\n",
    "                self.sync_checkpoint()\n",
    "            self.logger.info(\n",
    "                f\"Skill Manager retrieved skills for query:\\n ```\\n\"\n",
    "                f\"{query}\\n```\\n\"\n",
    "                f\"{', '.join(ret_skill_name)}\"\n",
    "            )\n",
    "\n",
    "            for skill_name in ret_skill_name:\n",
    "                retrieved_skill = {\n",
    "                    \"skill\": skill_name,\n",
    "                    \"description\": self.skills[skill_name][\"description\"],\n",
    "                    \"code\": self.skills[skill_name][\"full_code\"],\n",
    "                    \"marker\": self.skills[skill_name][\"marker\"],\n",
    "                }\n",
    "                ret_skill.append(retrieved_skill)\n",
    "        return ret_skill\n",
    "\n",
    "    def retrieve_skills_with_context(self, context):\n",
    "        ret_skill = []\n",
    "\n",
    "        k = min(len(self.skills), 6)\n",
    "        if k != 0:\n",
    "            self.logger.info(f\"Skill Manager retrieving for {k} skills\")\n",
    "            with self.skill_manager_lock:\n",
    "                query = context['formal_statement']\n",
    "                data = (\"skill_query\", {\"query\": query, \"k\": k})\n",
    "                outputs = self.chroma_bridge.run_cmd(data)\n",
    "                ret_skill_name = []\n",
    "                if outputs[\"error\"] is None:\n",
    "                    ret_skill_name = outputs[\"output\"]\n",
    "                self.sync_checkpoint()\n",
    "            self.logger.info(\n",
    "                f\"Skill Manager retrieved skills for query:\\n ```\\n\"\n",
    "                f\"{query}\\n```\\n\"\n",
    "                f\"{', '.join(ret_skill_name)}\"\n",
    "            )\n",
    "        \n",
    "            for skill_name in ret_skill_name:\n",
    "                retrieved_skill = {\n",
    "                    \"skill\": skill_name,\n",
    "                    \"description\": self.skills[skill_name][\"description\"],\n",
    "                    \"code\": self.skills[skill_name][\"full_code\"],\n",
    "                    \"marker\": self.skills[skill_name][\"marker\"],\n",
    "                }\n",
    "                ret_skill.append(retrieved_skill)\n",
    "\n",
    "        return ret_skill\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fe13d38-0674-44db-bb45-990e035f82a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "\n",
    "# import lego_prover.utils as U \n",
    "# from lego_prover.prompts import load_context\n",
    "import multiprocessing as mp\n",
    "\n",
    "import logging\n",
    "\n",
    "class CurriculumAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        logger=None,\n",
    "        ckpt_dir=\"ckpt\",\n",
    "        resume=False,\n",
    "        miniF2F_tasks : mp.Queue = None,\n",
    "        curriculum_task_type : str = \"simple_curriculum\",\n",
    "        curriculum_agent_lock = WithEmpty()\n",
    "    ):\n",
    "        self.logger=logger\n",
    "        self.miniF2F_tasks = miniF2F_tasks\n",
    "        self.curriculum_task_type = curriculum_task_type\n",
    "        self.curriculum_agent_lock = curriculum_agent_lock\n",
    "        self.ckpt_dir = ckpt_dir\n",
    "        f_mkdir(f\"{ckpt_dir}/curriculum/vectordb\")\n",
    "        if resume:\n",
    "            self.logger.info(f\"Loading Curriculum Agent from {ckpt_dir}/curriculum\")\n",
    "            self.sync_checkpoint()\n",
    "        else:\n",
    "            self.completed_tasks = []\n",
    "            self.failed_tasks = []\n",
    "    \n",
    "    def sync_checkpoint(self,):\n",
    "        if os.path.exists(f\"{self.ckpt_dir}/curriculum/completed_tasks.json\"):\n",
    "            self.completed_tasks = load_json(f\"{self.ckpt_dir}/curriculum/completed_tasks.json\")\n",
    "        if os.path.exists(f\"{self.ckpt_dir}/curriculum/failed_tasks.json\"):\n",
    "            self.failed_tasks = load_json(f\"{self.ckpt_dir}/curriculum/failed_tasks.json\")\n",
    "\n",
    "    @property\n",
    "    def easy_to_hard_curriculum(self):\n",
    "        result = []\n",
    "        for name in os.listdir(\"data/full_data/valid\"):\n",
    "            path = os.path.join(\"data/full_data/valid\", name)\n",
    "            context = load_json(path)\n",
    "            result.append((path, len(context[\"informal_proof\"])))\n",
    "        result = sorted(result, key=lambda x: x[1])\n",
    "        result = [x[0] for x in result]\n",
    "        return result\n",
    "\n",
    "    @property\n",
    "    def progress(self):\n",
    "        return len(self.completed_tasks)\n",
    "\n",
    "    def propose_next_task(self, max_retries=5, idx=None):\n",
    "        if self.curriculum_task_type == \"example\":\n",
    "            filename = os.listdir(\"data/examples\")[self.progress]\n",
    "            task = filename[:-5]\n",
    "            context = load_context(problem_name=os.path.join(\"data/examples\", filename))\n",
    "            return task, context\n",
    "        elif self.curriculum_task_type == \"simple_curriculum\":\n",
    "            assert idx is not None\n",
    "            file_path = self.easy_to_hard_curriculum[idx]\n",
    "            task = file_path\n",
    "            context = load_context(file_path)\n",
    "            return task, context\n",
    "        elif self.curriculum_task_type == \"queue_curriculum\":\n",
    "            while True:\n",
    "                if self.miniF2F_tasks.qsize() == 0:\n",
    "                    return \"\", None\n",
    "                file_path = self.miniF2F_tasks.get()\n",
    "                context = load_context(file_path)\n",
    "                if file_path not in self.completed_tasks:\n",
    "                    break\n",
    "            return file_path, context\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def get_task_retry_count(self, task):\n",
    "        cnt = 0\n",
    "        for t in self.failed_tasks:\n",
    "            if t == task:\n",
    "                cnt += 1\n",
    "        return cnt\n",
    "\n",
    "    def propose_next_manual_task(self):\n",
    "        confirmed = False\n",
    "        task = \"\"\n",
    "        while not confirmed:\n",
    "            task = input(\"Enter task: \")\n",
    "            print(f\"Task: {task}\")\n",
    "            confirmed = input(\"Confirm? (y/n)\").lower() in [\"y\", \"\"]\n",
    "        context = load_context(task)\n",
    "        return task, context\n",
    "\n",
    "    def update_exploration_progress(self, info):\n",
    "        with self.curriculum_agent_lock:\n",
    "            self.sync_checkpoint()\n",
    "\n",
    "            task = info[\"task\"]\n",
    "            if info[\"success\"]:\n",
    "                self.logger.info(f\"Completed task {task}.\")\n",
    "                self.completed_tasks.append(task)\n",
    "            else:\n",
    "                self.logger.info(\n",
    "                    f\"Failed to complete task {task}. Skipping to next task.\"\n",
    "                )\n",
    "                self.failed_tasks.append(task)\n",
    "\n",
    "            # clean up tasks and dump to disk\n",
    "            self.clean_up_tasks()\n",
    "\n",
    "    def clean_up_tasks(self):\n",
    "        updated_completed_tasks = []\n",
    "        # record repeated failed tasks\n",
    "        updated_failed_tasks = self.failed_tasks\n",
    "        # dedup but keep order\n",
    "        for task in self.completed_tasks:\n",
    "            if task not in updated_completed_tasks:\n",
    "                updated_completed_tasks.append(task)\n",
    "\n",
    "        # remove completed tasks from failed tasks\n",
    "        for task in updated_completed_tasks:\n",
    "            while task in updated_failed_tasks:\n",
    "                updated_failed_tasks.remove(task)\n",
    "\n",
    "        self.completed_tasks = updated_completed_tasks\n",
    "        self.failed_tasks = updated_failed_tasks\n",
    "\n",
    "        # dump to json\n",
    "        dump_json(\n",
    "            self.completed_tasks, f\"{self.ckpt_dir}/curriculum/completed_tasks.json\"\n",
    "        )\n",
    "        dump_json(self.failed_tasks, f\"{self.ckpt_dir}/curriculum/failed_tasks.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "673051f5-0be4-4f28-8549-378df160486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import tiktoken\n",
    "from lego_prover.env.isa_bridge import IsabelleEnv\n",
    "\n",
    "# import lego_prover.utils as U\n",
    "\n",
    "# from .agents import ActionAgent\n",
    "# from .agents import CurriculumAgent\n",
    "# from .agents import SkillManager\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "import logging\n",
    "\n",
    "\n",
    "class Prover:\n",
    "    def __init__(\n",
    "        self,\n",
    "        rank: int = None,\n",
    "        isabelle_path: str = None,\n",
    "        server_port: int = 8000,\n",
    "        model_name: str = \"gpt-4\",\n",
    "        temperature: int = 0,\n",
    "        action_agent_task_max_retries: int = 4,\n",
    "        curriculum_task_type: str = \"simple_curriculum\",\n",
    "        curriculum_agent_lock = WithEmpty(),\n",
    "        skill_manager_lock = WithEmpty(),\n",
    "        chroma_bridge = None,\n",
    "        openai_api_request_timeout: int = 6000,\n",
    "        ckpt_dir: str = \"ckpt\",\n",
    "        resume: bool = False,\n",
    "        miniF2F_tasks: mp.Queue = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes a new instance of the Prover class.\n",
    "\n",
    "        Args:\n",
    "            rank (int): The rank of the prover process.\n",
    "            isabelle_path (str): The path to the Isabelle directory.\n",
    "            server_port (int): The port number for the server.\n",
    "            model_name (str): The name of the OpenAI model to use.\n",
    "            temperature (int): The temperature for sampling the LLM.\n",
    "            action_agent_task_max_retries (int): The maximum number of retries for an action agent task.\n",
    "            curriculum_task_type (str): The type of curriculum task to use.\n",
    "            curriculum_agent_lock: The lock for the curriculum agent.\n",
    "            skill_manager_lock: The lock for the skill manager.\n",
    "            chroma_bridge: The ChromaBridge object for controlling the keyboard and mouse.\n",
    "            openai_api_request_timeout (int): The timeout for OpenAI API requests.\n",
    "            ckpt_dir (str): The directory for saving checkpoints.\n",
    "            resume (bool): Whether to resume from the checkpoint.\n",
    "            miniF2F_tasks (mp.Queue): The queue for miniF2F tasks.\n",
    "        \"\"\"\n",
    "\n",
    "        # init env\n",
    "        self.rank = rank\n",
    "        self.logger = logging.getLogger(f'prover-{rank}')\n",
    "        self.logger.info(f\"lego_prover running in rank {rank}\")\n",
    "        self.model_name = model_name\n",
    "\n",
    "        self.env = IsabelleEnv(\n",
    "            logger=self.logger,\n",
    "            isabelle_path=isabelle_path,\n",
    "            server_port=server_port\n",
    "        )\n",
    "        self.action_agent_model_name = model_name\n",
    "        self.tokenizer_encoder = tiktoken.encoding_for_model(\n",
    "            self.action_agent_model_name)\n",
    "\n",
    "        self.ckpt_dir = ckpt_dir\n",
    "        self.temperature = temperature\n",
    "\n",
    "        # init agents\n",
    "        self.action_agent = ActionAgent(\n",
    "            logger=self.logger,\n",
    "            model_name=model_name,\n",
    "            temperature=temperature,\n",
    "            request_timeout=openai_api_request_timeout,\n",
    "            ckpt_dir=ckpt_dir,\n",
    "        )\n",
    "        self.action_agent_task_max_retries = action_agent_task_max_retries\n",
    "        self.curriculum_agent = CurriculumAgent(\n",
    "            logger=self.logger,\n",
    "            ckpt_dir=ckpt_dir,\n",
    "            resume=resume,\n",
    "            miniF2F_tasks=miniF2F_tasks,\n",
    "            curriculum_task_type=curriculum_task_type,\n",
    "            curriculum_agent_lock=curriculum_agent_lock,\n",
    "        )\n",
    "        self.skill_manager = SkillManager(\n",
    "            rank=rank,\n",
    "            logger=self.logger,\n",
    "            ckpt_dir=ckpt_dir,\n",
    "            skill_manager_lock=skill_manager_lock,\n",
    "            chroma_bridge=chroma_bridge,\n",
    "        )\n",
    "        self.resume = resume\n",
    "\n",
    "        # init variables for rollout\n",
    "        self.action_agent_rollout_num_iter = -1\n",
    "        self.task = None\n",
    "        self.context = \"\"\n",
    "        self.messages = None\n",
    "        self.conversations = []\n",
    "        self.last_events = None\n",
    "\n",
    "    def _fill_skills(self, retrieved_skills, requested_skills, n_retrieved, n_requested, model_name):\n",
    "        \"\"\"\n",
    "        Given the retrieved skills query by problem statement and requests, output `n_retrieved + n_requested`\n",
    "        skill examples.\n",
    "        \"\"\"\n",
    "        if model_name == \"gpt-4\":\n",
    "            raise NotImplementedError\n",
    "\n",
    "        skills = random.sample(retrieved_skills, min(n_retrieved, len(self.retrieved_skills))) + \\\n",
    "            random.sample(requested_skills, min(\n",
    "                n_requested, len(self.requested_skills)))\n",
    "\n",
    "        skill_names = [skill[\"skill\"] for skill in skills]\n",
    "        n_skill = n_retrieved + n_requested\n",
    "        if len(skills) < n_skill:\n",
    "            for s in requested_skills:\n",
    "                if len(skills) == n_skill:\n",
    "                    break\n",
    "                if s[\"skill\"] not in skill_names:\n",
    "                    skills.append(s)\n",
    "            for s in retrieved_skills:\n",
    "                if len(skills) == n_skill:\n",
    "                    break\n",
    "                if s[\"skill\"] not in skill_names:\n",
    "                    skills.append(s)\n",
    "        self.logger.info(f\"There are {len(skills)} in total\")\n",
    "        return skills\n",
    "\n",
    "    def reset(self, task, context, reset_env=True):\n",
    "        self.context = context\n",
    "        self.action_agent_rollout_num_iter = 0\n",
    "        self.task = task\n",
    "        if reset_env:\n",
    "            self.env.reset()\n",
    "\n",
    "        self.retrieved_skills = self.skill_manager.retrieve_skills_with_context(\n",
    "            context=context)\n",
    "        self.informal_proof, skill_requests, conversation = self.action_agent.decomposer(\n",
    "            context=context,\n",
    "        )\n",
    "        self.info = {\"decomposer_conversation\": conversation}\n",
    "        for request in skill_requests:\n",
    "            request_name = self.env.get_lemma_name(request)\n",
    "            self.logger.info(\n",
    "                f\"adding request: name: {request_name}, code: {request}\")\n",
    "            self.skill_manager.add_new_request(\n",
    "                problem_name=task, formal_statement=request, init_update_count=0)\n",
    "\n",
    "        # request skill\n",
    "        self.requested_skills = []\n",
    "        requested_skills_name = [s[\"skill\"] for s in self.retrieved_skills]\n",
    "        for skill_context in skill_requests:\n",
    "            name = self.env.get_lemma_name(skill_context)\n",
    "            query = f\"code: {skill_context}, skill: {name}\"\n",
    "            requested_skill = self.skill_manager.retrieve_skills(query, 2)\n",
    "            self.logger.info(\n",
    "                f\"Skill request query: {query} with result {requested_skill}\")\n",
    "            for rskill in requested_skill:\n",
    "                if rskill[\"skill\"] not in requested_skills_name:\n",
    "                    requested_skills_name.append(rskill[\"skill\"])\n",
    "                    self.requested_skills.append(rskill)\n",
    "        self.logger.info(\n",
    "            f\"There are {len(skill_requests)} with result of {len(self.requested_skills)} requested skill retrieved\")\n",
    "\n",
    "        system_message = self.action_agent.render_formalizer_system_message()\n",
    "        skills = self._fill_skills(\n",
    "            self.retrieved_skills, self.requested_skills, 0, 4, self.model_name)\n",
    "\n",
    "        human_message = self.action_agent.render_formalizer_human_message(\n",
    "            skills=skills, context=context, informal_proof=self.informal_proof, n_example=2\n",
    "        )\n",
    "        self.messages = [system_message, human_message]\n",
    "        self.logger.info(\n",
    "            f\"****formalizer system message****\\n{system_message.content}\"\n",
    "        )\n",
    "        assert len(self.messages) == 2\n",
    "        self.conversations = []\n",
    "        self.history_messages = []\n",
    "        return self.messages\n",
    "\n",
    "    def close(self):\n",
    "        self.env.close()\n",
    "\n",
    "    def step(self):\n",
    "        if self.action_agent_rollout_num_iter < 0:\n",
    "            raise ValueError(\"Agent must be reset before stepping\")\n",
    "        skill_codes = []\n",
    "\n",
    "        conversation = {\"action_agent_sys0\": self.messages[0].content,\n",
    "                        \"action_agent_human0\": self.messages[1].content}\n",
    "        # query model\n",
    "        n_retry = 3\n",
    "        while n_retry > 0:\n",
    "            try:\n",
    "                self.logger.info(\n",
    "                    f\"****formalizer human message****\\n{self.messages[-1].content}\"\n",
    "                )\n",
    "                ai_message = self.action_agent.llm(\n",
    "                    self.messages, temperature=self.temperature, max_tokens=2000)\n",
    "                conversation[f\"action_agent_ai{3 - n_retry}\"] = ai_message.content\n",
    "                self.logger.info(\n",
    "                    f\"****formalizer ai message****\\n{ai_message.content}\")\n",
    "                # text = ai_message.content[ai_message.content.index(\"# Formalized code\"):]\n",
    "                text = ai_message.content\n",
    "                if \"####################\" in text:\n",
    "                    text = text[:text.index(\"####################\")]\n",
    "                code_pattern = re.compile(\n",
    "                    r\"```(?:[i|I]sabelle)(.*?)```\", re.DOTALL)\n",
    "                parsed_result = \"\\n\".join(code_pattern.findall(text)).strip()\n",
    "                assert self.context[\"formal_statement\"] in parsed_result, \\\n",
    "                    \"Formal statement is not in the formal code generated\"\n",
    "                break\n",
    "            except AssertionError as e:\n",
    "                if \"query too long\" in str(e):\n",
    "                    self.logger.info(str(e))\n",
    "                    parsed_result = False\n",
    "                    context_length = len(self.messages[1].content)\n",
    "                    self.messages[1] = HumanMessage(\n",
    "                        content=self.messages[1].content[int(context_length * 0.3):])\n",
    "                    n_retry -= 1\n",
    "                    conversation[f\"formalizer{3 - n_retry}\"] = self.messages[1].content\n",
    "                else:\n",
    "                    self.logger.info(f\"parse failed with error: {str(e)}\")\n",
    "                    parsed_result = False\n",
    "                    skills = self._fill_skills(\n",
    "                        self.retrieved_skills, self.requested_skills, 0, 4, self.model_name)\n",
    "                    human_message = self.action_agent.render_formalizer_human_message(\n",
    "                        skills=skills, context=self.context, informal_proof=self.informal_proof, n_example=2\n",
    "                    )\n",
    "                    n_retry -= 1\n",
    "                    conversation[f\"formalizer{3 - n_retry}\"] = self.messages[1].content\n",
    "                    self.messages[1] = human_message\n",
    "            except Exception as e:\n",
    "                self.logger.info(f\"parse failed with error: {str(e)}\")\n",
    "                parsed_result = False\n",
    "                skills = self._fill_skills(\n",
    "                    self.retrieved_skills, self.requested_skills, 0, 4, self.model_name)\n",
    "                human_message = self.action_agent.render_formalizer_human_message(\n",
    "                    skills=skills, context=self.context, informal_proof=self.informal_proof, n_example=2\n",
    "                )\n",
    "                n_retry -= 1\n",
    "                conversation[f\"formalizer{3 - n_retry}\"] = self.messages[1].content\n",
    "                self.messages[1] = human_message\n",
    "                time.sleep(5)\n",
    "\n",
    "        self.history_messages += [self.messages[1], ai_message]\n",
    "        self.conversations.append(\n",
    "            (self.messages[0].content,\n",
    "             self.messages[1].content, ai_message.content)\n",
    "        )\n",
    "        if isinstance(parsed_result, str):\n",
    "            self.logger.info(\"*******Parse success, verifying result*******\")\n",
    "            verified_result, parsed_result, skill_codes, requests = self.env.step(\n",
    "                parsed_result, formal_statement=self.context[\"formal_statement\"])\n",
    "            self.logger.info(f'Success: {verified_result[\"success\"]}')\n",
    "            self.logger.info(f'Error: {verified_result[\"reason\"]}')\n",
    "            if len(requests) > 10:\n",
    "                self.logger.warn(\n",
    "                    f\"Too many request! with {len(requests)} in total\")\n",
    "                requests = random.sample(requests, 10)\n",
    "            for req in requests:\n",
    "                self.skill_manager.add_new_request(\n",
    "                    problem_name=self.task,\n",
    "                    formal_statement=req,\n",
    "                    init_update_count=-3,\n",
    "                )\n",
    "        else:\n",
    "            assert isinstance(parsed_result, bool)\n",
    "            self.logger.warn(f\"{parsed_result} Trying again!\")\n",
    "            verified_result = {\"success\": False}\n",
    "        assert len(self.messages) == 2\n",
    "        self.action_agent_rollout_num_iter += 1\n",
    "        done = True\n",
    "        info = {\n",
    "            \"task\": self.task,\n",
    "            \"success\": verified_result[\"success\"],\n",
    "            \"conversations\": self.conversations,\n",
    "            \"code\": parsed_result,\n",
    "            \"context\": self.context,\n",
    "            \"verified_result\": verified_result,\n",
    "            \"action_agent_conversation\": conversation\n",
    "        }\n",
    "        self.info.update(info)\n",
    "        return self.messages, 0, done, self.info, skill_codes\n",
    "\n",
    "    def rollout(self, *, task, context, reset_env=True, gt_formal_code=None):\n",
    "        all_skill_codes = []\n",
    "        self.reset(task=task, context=context, reset_env=reset_env)\n",
    "        while True:\n",
    "            messages, reward, done, info, skill_codes = self.step()\n",
    "            all_skill_codes.extend(skill_codes)\n",
    "            if done or gt_formal_code is not None:\n",
    "                break\n",
    "\n",
    "        if info[\"success\"] is True:\n",
    "            self.logger.info(\"########## Final result ##########\")\n",
    "            self.logger.info(f'{info[\"code\"]}')\n",
    "            self.logger.info(\"##################################\")\n",
    "        else:\n",
    "            self.logger.info(\"########## Final result ##########\")\n",
    "            self.logger.info('sad!!!!!')\n",
    "            self.logger.info(\"##################################\")\n",
    "\n",
    "        # -- deduplicate according to the marker\n",
    "        if len(all_skill_codes) > 0:\n",
    "            markers, full_codes = list(zip(*all_skill_codes))\n",
    "            dedup_set = set()\n",
    "            all_skill_codes = []\n",
    "            for ix, marker in enumerate(markers):\n",
    "                if marker in dedup_set:\n",
    "                    continue\n",
    "                dedup_set.add(marker)\n",
    "                all_skill_codes.append([marker, full_codes[ix]])\n",
    "\n",
    "        if len(all_skill_codes) > 10:\n",
    "            self.logger.warn(\n",
    "                f\"There are {len(all_skill_codes)} to be added, it's problematic!! skipping...\")\n",
    "            all_skill_codes = random.sample(all_skill_codes, 10)\n",
    "\n",
    "        # self.skill_manager.conclude_skills(context, info, all_skill_codes)\n",
    "        for marker, full_code in all_skill_codes:\n",
    "            code = f'''theory Scratch\\n  imports Complex_Main\\nbegin\\n\\n{full_code}\\nend'''\n",
    "            result, *_ = self.env.step(code, quick_check=True)\n",
    "            if result is True:\n",
    "                self.skill_manager.add_new_skill(\n",
    "                    skill_name=self.env.get_lemma_name(marker),\n",
    "                    description=\"\",\n",
    "                    marker=marker,\n",
    "                    full_code=full_code,\n",
    "                    origin=f\"{task}_v{self.curriculum_agent.get_task_retry_count(task)}\",\n",
    "                    init_update_count=-1,\n",
    "                )\n",
    "\n",
    "        return messages, reward, done, info\n",
    "\n",
    "    def learn(self, reset_env=True):\n",
    "        while True:\n",
    "            task, context = self.curriculum_agent.propose_next_task(\n",
    "                max_retries=5)\n",
    "            if task is None:\n",
    "                break\n",
    "\n",
    "            task_retried_cnt = self.curriculum_agent.get_task_retry_count(task)\n",
    "            self.logger.info(\n",
    "                f\"Starting task {task} at {task_retried_cnt + 1} try and for at most {self.action_agent_task_max_retries} error correction\"\n",
    "            )\n",
    "            try:\n",
    "                messages, reward, done, info = self.rollout(\n",
    "                    task=task,\n",
    "                    context=context,\n",
    "                    reset_env=reset_env,\n",
    "                )\n",
    "            except TabError as e:\n",
    "                info = {\n",
    "                    \"task\": task,\n",
    "                    \"success\": False,\n",
    "                }\n",
    "                # reset isabelle\n",
    "                self.env.reset(hard_reset=True)\n",
    "                time.sleep(3)  # wait for prior programme to init\n",
    "                # use red color background to print the error\n",
    "                self.logger.info(\n",
    "                    \"Your last round rollout terminated due to error:\")\n",
    "                self.logger.info(f\"\\033[41m{e}\")\n",
    "\n",
    "            self.curriculum_agent.update_exploration_progress(info)\n",
    "            self.logger.info(\n",
    "                f\"Completed tasks: {', '.join(self.curriculum_agent.completed_tasks)}\"\n",
    "            )\n",
    "            self.logger.info(\n",
    "                f\"Failed tasks: {', '.join(self.curriculum_agent.failed_tasks)}\"\n",
    "            )\n",
    "\n",
    "            n_complete_task = len(set(list(filter(\n",
    "                lambda x: \"data/full_data\" in x, self.curriculum_agent.completed_tasks))))\n",
    "            n_failed_task = len(set(list(filter(\n",
    "                lambda x: \"data/full_data\" in x, self.curriculum_agent.failed_tasks))))\n",
    "\n",
    "            self.logger.info(f\"Number of completed tasks: {n_complete_task}\")\n",
    "            self.logger.info(f\"Number of failed tasks: {n_failed_task}\")\n",
    "            self.logger.info(\n",
    "                f\"pass rate: {n_complete_task / (n_complete_task + n_failed_task)}\")\n",
    "\n",
    "            print(f\"Success: {info['success']} - [{task}], try: {task_retried_cnt + 1},\",\n",
    "                  f\"Progress: {n_complete_task + n_failed_task}/244,\",\n",
    "                  f\"Sketch remaining: {self.curriculum_agent.miniF2F_tasks.qsize()}\"\n",
    "                  f\"Pass rate: {n_complete_task / (n_complete_task + n_failed_task)}\", flush=True)\n",
    "            os.makedirs(f\"{self.ckpt_dir}/json_logs\", exist_ok=True)\n",
    "            dump_json(\n",
    "                info, f\"{self.ckpt_dir}/json_logs/task_{context['problem_name']}_try{task_retried_cnt + 1}.json\")\n",
    "\n",
    "        return {\n",
    "            \"completed_tasks\": self.curriculum_agent.completed_tasks,\n",
    "            \"failed_tasks\": self.curriculum_agent.failed_tasks,\n",
    "            \"skills\": self.skill_manager.skills,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79b4484c-1e18-4ba6-ae72-f836a670c12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prover(rank, tasks, skill_manager_lock, curriculum_agent_lock, chroma_bridge):\n",
    "    server_port = 8051 + rank\n",
    "\n",
    "    prover = Prover(\n",
    "        rank=rank,\n",
    "        isabelle_path=isabelle_path,\n",
    "        server_port=server_port,\n",
    "        model_name=model_name,\n",
    "        skill_manager_lock=skill_manager_lock,\n",
    "        action_agent_task_max_retries=1,\n",
    "        curriculum_task_type=\"queue_curriculum\",\n",
    "        curriculum_agent_lock=curriculum_agent_lock,\n",
    "        resume=resume,\n",
    "        temperature=temperature,\n",
    "        miniF2F_tasks=tasks,\n",
    "        ckpt_dir=ckpt_dir,\n",
    "        chroma_bridge=chroma_bridge,\n",
    "    )\n",
    "    prover.learn()\n",
    "\n",
    "def run_evolver(rank, skill_manager_lock, chroma_bridge):\n",
    "    server_port = 8011 + rank\n",
    "    evolver = Evolver(\n",
    "        rank=rank,\n",
    "        isabelle_path=isabelle_path,\n",
    "        ckpt_dir=ckpt_dir,\n",
    "        server_port=server_port,\n",
    "        data_split=data_split,\n",
    "        skill_manager_lock=skill_manager_lock,\n",
    "        model_name=model_name,\n",
    "        temperature=temperature,\n",
    "        chroma_bridge=chroma_bridge\n",
    "    )\n",
    "    evolver.evolve()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "014711b6-bb83-44e5-b8f7-24d987535f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess chroma_worker started with PID 2433467.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2432657/2043160899.py:82: UserWarning: Subprocess chroma_worker failed to start.\n",
      "  warnings.warn(f\"Subprocess {self.name} failed to start.\")\n"
     ]
    }
   ],
   "source": [
    "# processes = []\n",
    "# skill_manager_lock = mp.Lock()\n",
    "# curriculum_agent_lock = mp.Lock()\n",
    "# chroma_bridge = ChromaBridge(ckpt_path=ckpt_dir, resume=resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ead610-2f9c-4480-80b3-aabca16ad495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess isabelle_server started with PID 2435733.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/huangyongfeng/ananke/example/pipeline/math_experiment/LEGO-Prover/lego_prover/env/process_monitor.py:80: UserWarning: Subprocess isabelle_server failed to start.\n",
      "  warnings.warn(f\"Subprocess {self.name} failed to start.\")\n",
      "\u001b[36m[2024-03-20 08:00:09,052] [Azure] [DEBUG] - azure\u001b[0m\n",
      "\u001b[36m[2024-03-20 08:00:09,052] [Azure] [DEBUG] - azure\u001b[0m\n",
      "\u001b[36m[2024-03-20 08:00:09,052] [Azure] [DEBUG] - azure\u001b[0m\n",
      "/workspace/huangyongfeng/ananke/example/pipeline/math_experiment/LEGO-Prover/lego_prover/env/process_monitor.py:80: UserWarning: Subprocess isabelle_server failed to start.\n",
      "  warnings.warn(f\"Subprocess {self.name} failed to start.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess isabelle_server started with PID 2435797.\n",
      "Subprocess isabelle_server started with PID 2435848.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/huangyongfeng/ananke/example/pipeline/math_experiment/LEGO-Prover/lego_prover/env/process_monitor.py:80: UserWarning: Subprocess isabelle_server failed to start.\n",
      "  warnings.warn(f\"Subprocess {self.name} failed to start.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess isabelle_server started with PID 2435890.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/huangyongfeng/ananke/example/pipeline/math_experiment/LEGO-Prover/lego_prover/env/process_monitor.py:80: UserWarning: Subprocess isabelle_server failed to start.\n",
      "  warnings.warn(f\"Subprocess {self.name} failed to start.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess isabelle_server started with PID 2435944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/huangyongfeng/ananke/example/pipeline/math_experiment/LEGO-Prover/lego_prover/env/process_monitor.py:80: UserWarning: Subprocess isabelle_server failed to start.\n",
      "  warnings.warn(f\"Subprocess {self.name} failed to start.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess isabelle_server started with PID 2436013.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/huangyongfeng/ananke/example/pipeline/math_experiment/LEGO-Prover/lego_prover/env/process_monitor.py:80: UserWarning: Subprocess isabelle_server failed to start.\n",
      "  warnings.warn(f\"Subprocess {self.name} failed to start.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess isabelle_server started with PID 2436108.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/huangyongfeng/ananke/example/pipeline/math_experiment/LEGO-Prover/lego_prover/env/process_monitor.py:80: UserWarning: Subprocess isabelle_server failed to start.\n",
      "  warnings.warn(f\"Subprocess {self.name} failed to start.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess isabelle_server started with PID 2436234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/huangyongfeng/ananke/example/pipeline/math_experiment/LEGO-Prover/lego_prover/env/process_monitor.py:80: UserWarning: Subprocess isabelle_server failed to start.\n",
      "  warnings.warn(f\"Subprocess {self.name} failed to start.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess isabelle_server started with PID 2436427.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/huangyongfeng/ananke/example/pipeline/math_experiment/LEGO-Prover/lego_prover/env/process_monitor.py:80: UserWarning: Subprocess isabelle_server failed to start.\n",
      "  warnings.warn(f\"Subprocess {self.name} failed to start.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess isabelle_server started with PID 2436752.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/huangyongfeng/ananke/example/pipeline/math_experiment/LEGO-Prover/lego_prover/env/process_monitor.py:80: UserWarning: Subprocess isabelle_server failed to start.\n",
      "  warnings.warn(f\"Subprocess {self.name} failed to start.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess isabelle_server started with PID 2437228.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/huangyongfeng/ananke/example/pipeline/math_experiment/LEGO-Prover/lego_prover/env/process_monitor.py:80: UserWarning: Subprocess isabelle_server failed to start.\n",
      "  warnings.warn(f\"Subprocess {self.name} failed to start.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess isabelle_server started with PID 2438213.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/huangyongfeng/ananke/example/pipeline/math_experiment/LEGO-Prover/lego_prover/env/process_monitor.py:80: UserWarning: Subprocess isabelle_server failed to start.\n",
      "  warnings.warn(f\"Subprocess {self.name} failed to start.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess isabelle_server started with PID 2439200.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/huangyongfeng/ananke/example/pipeline/math_experiment/LEGO-Prover/lego_prover/env/process_monitor.py:80: UserWarning: Subprocess isabelle_server failed to start.\n",
      "  warnings.warn(f\"Subprocess {self.name} failed to start.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess isabelle_server started with PID 2440128.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/huangyongfeng/ananke/example/pipeline/math_experiment/LEGO-Prover/lego_prover/env/process_monitor.py:80: UserWarning: Subprocess isabelle_server failed to start.\n",
      "  warnings.warn(f\"Subprocess {self.name} failed to start.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess isabelle_server started with PID 2440879.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/huangyongfeng/ananke/example/pipeline/math_experiment/LEGO-Prover/lego_prover/env/process_monitor.py:80: UserWarning: Subprocess isabelle_server failed to start.\n",
      "  warnings.warn(f\"Subprocess {self.name} failed to start.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess isabelle_server started with PID 2441836.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/huangyongfeng/ananke/example/pipeline/math_experiment/LEGO-Prover/lego_prover/env/process_monitor.py:80: UserWarning: Subprocess isabelle_server failed to start.\n",
      "  warnings.warn(f\"Subprocess {self.name} failed to start.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess isabelle_server started with PID 2442594.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/huangyongfeng/ananke/example/pipeline/math_experiment/LEGO-Prover/lego_prover/env/process_monitor.py:80: UserWarning: Subprocess isabelle_server failed to start.\n",
      "  warnings.warn(f\"Subprocess {self.name} failed to start.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess isabelle_server started with PID 2443654.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/huangyongfeng/ananke/example/pipeline/math_experiment/LEGO-Prover/lego_prover/env/process_monitor.py:80: UserWarning: Subprocess isabelle_server failed to start.\n",
      "  warnings.warn(f\"Subprocess {self.name} failed to start.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess isabelle_server started with PID 2444496.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/huangyongfeng/ananke/example/pipeline/math_experiment/LEGO-Prover/lego_prover/env/process_monitor.py:80: UserWarning: Subprocess isabelle_server failed to start.\n",
      "  warnings.warn(f\"Subprocess {self.name} failed to start.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess isabelle_server started with PID 2445495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/huangyongfeng/ananke/example/pipeline/math_experiment/LEGO-Prover/lego_prover/env/process_monitor.py:80: UserWarning: Subprocess isabelle_server failed to start.\n",
      "  warnings.warn(f\"Subprocess {self.name} failed to start.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess isabelle_server started with PID 2446488.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/huangyongfeng/ananke/example/pipeline/math_experiment/LEGO-Prover/lego_prover/env/process_monitor.py:80: UserWarning: Subprocess isabelle_server failed to start.\n",
      "  warnings.warn(f\"Subprocess {self.name} failed to start.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess isabelle_server started with PID 2447458.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/huangyongfeng/ananke/example/pipeline/math_experiment/LEGO-Prover/lego_prover/env/process_monitor.py:80: UserWarning: Subprocess isabelle_server failed to start.\n",
      "  warnings.warn(f\"Subprocess {self.name} failed to start.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess isabelle_server started with PID 2448263.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/huangyongfeng/ananke/example/pipeline/math_experiment/LEGO-Prover/lego_prover/env/process_monitor.py:80: UserWarning: Subprocess isabelle_server failed to start.\n",
      "  warnings.warn(f\"Subprocess {self.name} failed to start.\")\n"
     ]
    }
   ],
   "source": [
    "rank = 0\n",
    "run_prover(rank, miniF2F_tasks, skill_manager_lock, curriculum_agent_lock, chroma_bridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3402b550-272a-4b2e-9808-e8f3cd0de90c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
